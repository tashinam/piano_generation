{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "piano_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xdBShl-ef89a",
        "65CoOUxjgWWy",
        "4gjk1abUgiUs",
        "5JLUh1ORjUE8",
        "BEM_-ovgj7S-",
        "Pwa0XWgW0--Q"
      ],
      "machine_shape": "hm",
      "mount_file_id": "1ScB98KC595IceOKAvcTvU0d2i4PpESmX",
      "authorship_tag": "ABX9TyP45545otygj2qs4JkUdRDM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5dd2e5c29d64e37a62ea8f2aa349397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af9487df39c8411ca1ebd308dcdc76bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73176dcd180e4124980ab1c56bd45222",
              "IPY_MODEL_1c6268854aa1467b9e1ad679198c742f",
              "IPY_MODEL_11ae5dd836d14db993c65a904487dc05"
            ]
          }
        },
        "af9487df39c8411ca1ebd308dcdc76bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "73176dcd180e4124980ab1c56bd45222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_09e59be383fe45839d5138981b082d40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 0:  77%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09c0ae9775fd44b3a963a32b1dee2165"
          }
        },
        "1c6268854aa1467b9e1ad679198c742f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3292764e9f7a4e8aa249108ea8697686",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 390,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 300,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91e6591742af4c9d8641f41794c6c2ad"
          }
        },
        "11ae5dd836d14db993c65a904487dc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b2e59f50d4643fc850c79a7cab9a004",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 300/390 [01:09&lt;00:20,  4.29it/s, loss=-0.845, v_num=9]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7eb0621d38524a838965473ff5ae7cd8"
          }
        },
        "09e59be383fe45839d5138981b082d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09c0ae9775fd44b3a963a32b1dee2165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3292764e9f7a4e8aa249108ea8697686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91e6591742af4c9d8641f41794c6c2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b2e59f50d4643fc850c79a7cab9a004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7eb0621d38524a838965473ff5ae7cd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6251a4d59d9a42a49344fc48b935b7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a99937dcc5349e1b9349550f86886b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a79d1afb35f467ebfadb67f49773dac",
              "IPY_MODEL_f19577612f8d44bda00a09717934a408"
            ]
          }
        },
        "6a99937dcc5349e1b9349550f86886b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a79d1afb35f467ebfadb67f49773dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a97c48c4188d4a7ca4e6bc2300d6a318",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5155f6a7e4b47a1849ca74c2997e4ee"
          }
        },
        "f19577612f8d44bda00a09717934a408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e94cd78ee914fcc8f0f2cf647461cd9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [12:11&lt;00:00, 731.72s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c9081b764eb4e5990d80713ed901627"
          }
        },
        "a97c48c4188d4a7ca4e6bc2300d6a318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5155f6a7e4b47a1849ca74c2997e4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e94cd78ee914fcc8f0f2cf647461cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c9081b764eb4e5990d80713ed901627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41b1bbae47564049881f16f824661941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c8107828c4248bd95f7051ae100f4db",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f962ee5586824e10b065061edcd4f9b8",
              "IPY_MODEL_713c48f878f54d3a97a5b458c6007dd2"
            ]
          }
        },
        "8c8107828c4248bd95f7051ae100f4db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f962ee5586824e10b065061edcd4f9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63720f367c5449c48c3be709069b11b1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 12,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9272d79ad21149e79676826c566f7eea"
          }
        },
        "713c48f878f54d3a97a5b458c6007dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4f4d26547544a23baa233d89419bc05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [12:11&lt;00:00, 60.95s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c1feeb0387a4472ad2ac3d56ede42e0"
          }
        },
        "63720f367c5449c48c3be709069b11b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9272d79ad21149e79676826c566f7eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4f4d26547544a23baa233d89419bc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c1feeb0387a4472ad2ac3d56ede42e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "446e93394a044c1dbd32f6f96931e986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07922e3f7faf45efaa6899a28a26cfe7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24cb35f4150443c7849966c1ae25208c",
              "IPY_MODEL_25d78080215b4765b38d3362f588b530",
              "IPY_MODEL_8077d1def65447dcbfc9358079a874df"
            ]
          }
        },
        "07922e3f7faf45efaa6899a28a26cfe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24cb35f4150443c7849966c1ae25208c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa57a7eeb00a4e5a950d761872aa0ff5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ce211543698483782268d7c1a2f239f"
          }
        },
        "25d78080215b4765b38d3362f588b530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f062c21fd1f43088ad71d7382d5146a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7efa29f7e4a4f2c9d0a2cc4cdba8bb2"
          }
        },
        "8077d1def65447dcbfc9358079a874df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40046cddf4ec4b8faa72e74d4f06b91c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:55&lt;00:00, 55.29s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c334530a88446668647bb777fbae042"
          }
        },
        "aa57a7eeb00a4e5a950d761872aa0ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ce211543698483782268d7c1a2f239f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f062c21fd1f43088ad71d7382d5146a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7efa29f7e4a4f2c9d0a2cc4cdba8bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40046cddf4ec4b8faa72e74d4f06b91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c334530a88446668647bb777fbae042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "519e30221409427c91c49f7d33c5b2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57dbe0e6068f4c86bfded4ee9fed1d60",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4389ee9e6f0b49519ae4c892d91cfff8",
              "IPY_MODEL_d7b3f5fe81974cb6b356c457b5b3832e",
              "IPY_MODEL_17bf0d82eba3412daf256e5c9d0ee48d"
            ]
          }
        },
        "57dbe0e6068f4c86bfded4ee9fed1d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4389ee9e6f0b49519ae4c892d91cfff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8f9dc14c3204b3c95558e31d8eb7a3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfa127db6ffa4b5ba06e3e265e653dad"
          }
        },
        "d7b3f5fe81974cb6b356c457b5b3832e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_48df61c7a94b4f0aaf17f9d5229815f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 40,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 40,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bb86e1ea53347ecb28fee31c9c5067d"
          }
        },
        "17bf0d82eba3412daf256e5c9d0ee48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fcc152e6df6446cea944ebda1fb6e862",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 40/40 [00:54&lt;00:00,  1.69s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e97109b22bb04d3b8476b04ded130ef7"
          }
        },
        "c8f9dc14c3204b3c95558e31d8eb7a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfa127db6ffa4b5ba06e3e265e653dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48df61c7a94b4f0aaf17f9d5229815f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bb86e1ea53347ecb28fee31c9c5067d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcc152e6df6446cea944ebda1fb6e862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e97109b22bb04d3b8476b04ded130ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tashinam/piano_generation/blob/main/piano_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuD0en9Ejga3"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QzIiVfcT0Lp"
      },
      "source": [
        "%%capture\n",
        "!pip install mido\n",
        "# !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install pytorch-lightning\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njVlKwOFLXlM"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ej9tziqLg0o",
        "outputId": "5271f9a5-4832-4603-8048-f283881afd60"
      },
      "source": [
        "%cd /content/piano_generation/\n",
        "!git stash\n",
        "!git pull\n",
        "%cd"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/piano_generation\n",
            "No local changes to save\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/tashinam/piano_generation\n",
            "   12bdb05..6c2a1f7  main       -> origin/main\n",
            "Updating 12bdb05..6c2a1f7\n",
            "Fast-forward\n",
            " models.py | 12 \u001b[32m++++++\u001b[m\u001b[31m------\u001b[m\n",
            " 1 file changed, 6 insertions(+), 6 deletions(-)\n",
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdI8edBETj0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7430e763-947d-4c7f-ab6d-e39c65a62f8c"
      },
      "source": [
        "import numpy as np\n",
        "import mido\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from torch.autograd import Variable\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import wandb\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from piano_generation.models import *\n",
        "from piano_generation.util import Maestro\n",
        "wandb.login()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtashinam\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts-juXU4jrHt"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZqwb3oLehwm"
      },
      "source": [
        "### Set Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BftSZVJCga0U"
      },
      "source": [
        "### VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i33iJOMaqTw"
      },
      "source": [
        "input_height = 88\n",
        "cond_height = 3\n",
        "conductor_height = 4\n",
        "num_conductors = 5\n",
        "conductor_2_height = 5\n",
        "num_conductors_2 = 20\n",
        "# conductor_3_height = 2\n",
        "# num_conductors_3 = 8\n",
        "seq_len = 100\n",
        "odd = False\n",
        "# input_height = 88+125\n",
        "# cond_height = 0\n",
        "# conductor_height = 10\n",
        "# num_conductors = 10\n",
        "# seq_len = 100\n",
        "# odd = True\n",
        "latent_dim = 256  \n",
        "enc_hidden_dim = 256\n",
        "hidden_dim= 256\n",
        "cond_len = 0\n",
        "input_len = seq_len + cond_len\n",
        "teacher_forcing_ratio = 0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P_fUWNVVS3x"
      },
      "source": [
        "class VAE(pl.LightningModule):\n",
        "\n",
        "    ###############################    \n",
        "    ############ setup ############\n",
        "    ###############################\n",
        "\n",
        "    def __init__(self, input_dim=input_height, hidden_dim=hidden_dim, latent_dim=latent_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        ### encoder & decoder networks\n",
        "        self.encoder = lstm_encoder(input_size=input_dim, hidden_size=enc_hidden_dim, output_size=enc_hidden_dim, batch_size=batch_size)\n",
        "        # self.vq = VectorQuantizerEMA(num_embeddings=1024, embedding_dim=8, commitment_cost=0.25, decay=0.99)\n",
        "        # self.vq = VectorQuantizer(num_embeddings=1024, embedding_dim=4, commitment_cost=0.25)\n",
        "        self.conductor = lstm_conductor(input_size=latent_dim, hidden_size=hidden_dim, output_size=latent_dim, batch_size=batch_size)\n",
        "        self.conductor_2 = lstm_conductor(input_size=latent_dim, hidden_size=hidden_dim, output_size=latent_dim, batch_size=batch_size)\n",
        "        # self.conductor_3 = lstm_conductor(input_size=latent_dim, hidden_size=hidden_dim, output_size=latent_dim, batch_size=batch_size)\n",
        "        self.decoder = lstm_decoder(input_size=latent_dim, hidden_size=hidden_dim, output_size=latent_dim, batch_size=batch_size)\n",
        "\n",
        "        ### latent distribution parameters\n",
        "        self.fc_mu = nn.Linear((self.encoder.bidirectional+1)*enc_hidden_dim, latent_dim)\n",
        "        self.fc_var = nn.Linear((self.encoder.bidirectional+1)*enc_hidden_dim, latent_dim)\n",
        "\n",
        "        ### output \n",
        "        self.fc_out = nn.Linear(latent_dim, input_dim)\n",
        "        # self.fc_cond = nn.Linear(latent_dim, latent_dim)\n",
        "        # self.fc_out = nn.Linear(latent_dim, latent_dim)\n",
        "        # self.tanh = nn.Tanh()\n",
        "        # self.loss = nn.NLLLoss()\n",
        "        # self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "        ### variance for the Gaussian likelihood\n",
        "        self.log_scale = nn.Parameter(torch.Tensor([-2.6]))\n",
        "\n",
        "        ### kl-divergence weighting\n",
        "        self.beta=1e-4\n",
        "\n",
        "        ### save hyperparameters for lightning checkpoints\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    ### configure pytorch optimizer\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "    ### reconstruction loss calculated as gaussian likelihood of drawing input vector from predicted vector \n",
        "    def gaussian_likelihood(self, mean, logscale, sample):\n",
        "        scale = torch.exp(logscale)\n",
        "        dist = torch.distributions.Normal(mean, scale)\n",
        "        log_pxz = dist.log_prob(sample)\n",
        "        # return log_pxz.sum()\n",
        "        return log_pxz.mean()\n",
        "\n",
        "    ### reparameterization trick to add noise to variance for backpropagation\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return (eps * std) + mu\n",
        "\n",
        "    ### kl-divergence calculated by monte-carlo estimation\n",
        "    def kl_divergence(self, z, mu, log_var):\n",
        "        std = torch.exp(log_var / 2)\n",
        "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std)) \n",
        "        q = torch.distributions.Normal(mu, std)\n",
        "        log_qzx = q.log_prob(z)\n",
        "        log_pz = p.log_prob(z)\n",
        "        kl = (log_qzx - log_pz)\n",
        "        kl = kl.mean(-1)\n",
        "        return kl\n",
        "\n",
        "\n",
        "    ############################################    \n",
        "    ############ training procedure ############\n",
        "    ############################################\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \n",
        "        ### separate input data and condition\n",
        "        x = batch\n",
        "        # x, cond = batch \n",
        "        if odd:\n",
        "          x = x[:,:-1,:]\n",
        "\n",
        "        ###### ENCODER ######\n",
        "\n",
        "        ### reset encoder hidden and cell state each batch\n",
        "        encoder_hidden = self.encoder.init_hidden(device=self.device)\n",
        "\n",
        "        ###### either FOR LOOP ...\n",
        "\n",
        "        # ### encode x to get the mu and variance parameters \n",
        "        # encoder_outputs = torch.zeros(batch_size, seq_len, self.encoder.hidden_size, device=self.device) \n",
        "        # for c in range(cond_len): # get hidden states for the conditions\n",
        "        #   _, encoder_hidden = self.encoder(cond[:,c,:].unsqueeze(1), encoder_hidden) # get the current step of the sequence and force sequence dimension to remain with size 1\n",
        "        # for s in range(seq_len): # get outputs as well as hidden and cell states for the rest of the sequence\n",
        "        #     encoder_output, encoder_hidden = self.encoder(x[:,s,:].unsqueeze(1), encoder_hidden) # get the current step of the sequence and force sequence dimension to remain with size 1\n",
        "        #     encoder_outputs[:,s] = encoder_output.squeeze(1) # stack each step of sequence back into a tensor\n",
        "\n",
        "        ###### or TENSORIZED ...\n",
        "\n",
        "        ### concatenate input and condition\n",
        "        # input_cond = torch.zeros((batch_size, 1, input_height), device=self.device)\n",
        "        # input_cond[:,:,:cond_height] = cond\n",
        "        # x_input = torch.cat((input_cond,x),1) # concat along sequence dimension (1)\n",
        "        x_input = x\n",
        "\n",
        "        ### encode x to get the mu and variance parameters as a tensor \n",
        "        _, encoder_hidden = self.encoder(x_input, encoder_hidden)\n",
        "\n",
        "        # get hidden state [0] but not cell state [1], swap batch to first index and get last layer only\n",
        "        if self.encoder.bidirectional:\n",
        "          x_encoded = encoder_hidden[0].transpose(0,1)[:,-2:,:].reshape(batch_size,1,self.encoder.hidden_size*2) # concat both directions of last hidden layer\n",
        "        else:\n",
        "          x_encoded = encoder_hidden[0].transpose(0,1)[:,-1,:].unsqueeze(1)\n",
        "          \n",
        "\n",
        "        ###### ... end ######\n",
        "        \n",
        "\n",
        "        ###### LATENT SPACE ######\n",
        "\n",
        "        ### get latent space vector\n",
        "        if vq:\n",
        "          mu = self.fc_mu(x_encoded)\n",
        "          vq_loss, z, perplexity, _ = self.vq(mu)\n",
        "        else: \n",
        "          mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
        "          z = self.reparameterize(mu, log_var)\n",
        "\n",
        "        # latent_cond = torch.zeros((batch_size, 1, hidden_dim), device=self.device)\n",
        "        # latent_cond[:,:,:cond_height] = cond\n",
        "\n",
        "\n",
        "        ###### CONDUCTOR ######\n",
        "\n",
        "        #### code here for conductor model from musicvae paper\n",
        "\n",
        "        ### initialize output tensor\n",
        "        conductor_hidden = self.conductor.init_hidden(device=self.device)\n",
        "        conductor_outputs = torch.zeros((batch_size, conductor_height*num_conductors, latent_dim), device=self.device)\n",
        "\n",
        "        ### get hidden and cell state (but not output) for conditions\n",
        "        # for c in range(cond_len): \n",
        "        # _, conductor_hidden = self.decoder(latent_cond, conductor_hidden) \n",
        "\n",
        "        ### get outputs and hidden and cell state for rest of sequence\n",
        "        for s in range(conductor_height): \n",
        "          if s==0: # first input is always the latent vector\n",
        "            conductor_input = z\n",
        "          \n",
        "          conductor_output, conductor_hidden = self.conductor(conductor_input, conductor_hidden)\n",
        "          conductor_outputs[:,s] = conductor_output.squeeze(1)\n",
        "\n",
        "          if s<seq_len-1: # subsequent inputs. Don't need to get another input after last decoding\n",
        "            # conductor_input = F.one_hot(torch.argmax(conductor_output,-1),latent_dim).type(torch.FloatTensor).to(self.device)\n",
        "            conductor_input = conductor_output\n",
        "\n",
        "\n",
        "        ###### CONDUCTOR 2 ######\n",
        "        ### initialize output tensor\n",
        "        conductor_2_outputs = torch.zeros((batch_size, conductor_2_height*num_conductors_2, latent_dim), device=self.device) \n",
        "        ### get outputs and hidden and cell state for rest of sequence\n",
        "        for c in range(num_conductors): \n",
        "          conductor_2_hidden = self.conductor_2.init_hidden(device=self.device)\n",
        "          for s in range(conductor_height): \n",
        "              if s==0: # first input is always the latent vector\n",
        "                conductor_2_input = conductor_outputs[:,c].unsqueeze(1)\n",
        "              conductor_2_output, conductor_2_hidden = self.conductor_2(conductor_2_input, conductor_2_hidden)\n",
        "              conductor_2_outputs[:,(c*conductor_height)+s] = conductor_2_output.squeeze(1)\n",
        "          if s<seq_len-1: # subsequent inputs. Don't need to get another input after last decoding\n",
        "            conductor_2_input = conductor_2_output\n",
        "\n",
        "        # ###### CONDUCTOR 3 ######\n",
        "        # ### initialize output tensor\n",
        "        # conductor_3_outputs = torch.zeros((batch_size, conductor_3_height*num_conductors_3, latent_dim), device=self.device) \n",
        "        # ### get outputs and hidden and cell state for rest of sequence\n",
        "        # for c in range(num_conductors_2): \n",
        "        #   conductor_3_hidden = self.conductor_3.init_hidden(device=self.device)\n",
        "        #   for s in range(conductor_2_height): \n",
        "        #       if s==0: # first input is always the latent vector\n",
        "        #         conductor_3_input = conductor_2_outputs[:,c].unsqueeze(1)\n",
        "        #       conductor_3_output, conductor_3_hidden = self.conductor_3(conductor_3_input, conductor_3_hidden)\n",
        "        #       conductor_3_outputs[:,(c*conductor_2_height)+s] = conductor_3_output.squeeze(1)\n",
        "        #   if s<seq_len-1: # subsequent inputs. Don't need to get another input after last decoding\n",
        "        #     conductor_3_input = conductor_3_output\n",
        "\n",
        "\n",
        "\n",
        "        ###### DECODER ######\n",
        "\n",
        "        decoder_outputs = torch.zeros((batch_size, seq_len-odd, latent_dim), device=self.device)\n",
        "        zeros = torch.zeros((batch_size, 1, latent_dim), device=self.device)\n",
        "        # sub_x = torch.zeros((batch_size, conductor_height-1, latent_dim), device=self.device)\n",
        "\n",
        "        for c in range(num_conductors_2):\n",
        "          ### initialize hidden state tensors\n",
        "          decoder_hidden = self.decoder.init_hidden(device=self.device)\n",
        "\n",
        "          ###### either TEACHER FORCING TENSORIZED ...\n",
        "          # teacher_forcing = True if np.random.random() < teacher_forcing_ratio else False\n",
        "          teacher_forcing = False\n",
        "          if teacher_forcing:\n",
        "            pass\n",
        "            # # x_latent = torch.cat((latent_cond,z,x[:,1:,:]),1) # concat along sequence dimension (1)\n",
        "            # # print(x.shape, x[:,100])\n",
        "            # sub_x[:,:,:input_height] = x[:,(c*conductor_height)+1:((c+1)*conductor_height),:]\n",
        "            # # print(f'start: {(c*conductor_height)+1}, stop: {((c+1)*conductor_height)}, len: {seq_len}')\n",
        "            # # print(sub_x.shape, latent_cond.shape, conductor_outputs[:,c].shape)\n",
        "            # # print(sub_x.shape, latent_cond.shape, conductor_outputs[:,c].unsqueeze(1).shape)\n",
        "            # x_latent = torch.cat((latent_cond,conductor_outputs[:,c].unsqueeze(1),sub_x),1) # concat along sequence dimension (1)\n",
        "            # # x_latent = torch.cat((conductor_outputs[:,c].unsqueeze(1),sub_x),1) # no latent\n",
        "            # decoder_output, _ = self.decoder(x_latent, decoder_hidden)\n",
        "            \n",
        "            # # print(decoder_outputs[:,c*conductor_height:((c+1)*conductor_height),:].shape, decoder_output[:,cond_len:,:].shape)\n",
        "            # decoder_outputs[:,c*conductor_height:((c+1)*conductor_height),:] = decoder_output[:,cond_len:,:] # remove outputs from conditional vectors\n",
        "            # # decoder_outputs[:,c*conductor_height:((c+1)*conductor_height),:] = decoder_output # no latent\n",
        "\n",
        "          else: \n",
        "            ### get hidden and cell state (but not output) for conditions\n",
        "            # for c in range(cond_len): \n",
        "            # _, decoder_hidden = self.decoder(latent_cond, decoder_hidden) \n",
        "\n",
        "            ### get outputs and hidden and cell state for rest of sequence\n",
        "            for s in range(conductor_2_height): \n",
        "              if s==0: # first input is always the latent vector\n",
        "                decoder_input = conductor_2_outputs[:,c].unsqueeze(1)\n",
        "                # decoder_input = torch.cat((conductor_outputs[:,c].unsqueeze(1),zeros), dim=2)\n",
        "              \n",
        "              decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "              # decoder_output = self.output(decoder_output)\n",
        "              # decoder_output = self.softmax(decoder_output)\n",
        "              decoder_outputs[:,(c*conductor_2_height)+s] = decoder_output.squeeze(1)\n",
        "\n",
        "              if s<seq_len-1: # subsequent inputs. Don't need to get another input after last decoding\n",
        "                # decoder_input = F.one_hot(torch.argmax(decoder_output,-1),latent_dim).type(torch.FloatTensor).to(self.device)\n",
        "                # outmax = F.one_hot(torch.argmax(decoder_output,-1),latent_dim).type(torch.FloatTensor).to(self.device)\n",
        "                # decoder_input = torch.cat((conductor_outputs[:,c].unsqueeze(1), decoder_output), dim=2)\n",
        "                # decoder_input = torch.cat((conductor_outputs[:,c].unsqueeze(1), zeros), dim=2)\n",
        "                decoder_input = decoder_output\n",
        "\n",
        "        # ###### WITHOUT CONDUCTOR\n",
        "        # teacher_forcing = True if np.random.random() < teacher_forcing_ratio else False\n",
        "        # if teacher_forcing:\n",
        "        #   x_latent = torch.cat((latent_cond,z,x[:,1:,:]),1) # concat along sequence dimension (1)\n",
        "        #   decoder_output, _ = self.decoder(x_latent, decoder_hidden)\n",
        "        #   decoder_outputs = decoder_output[:,cond_len:,:]\n",
        "\n",
        "        # else: \n",
        "        #   ### initialize output tensor\n",
        "        #   decoder_outputs = torch.zeros((batch_size, seq_len, latent_dim), device=self.device)\n",
        "\n",
        "        #   ### get hidden and cell state (but not output) for conditions\n",
        "        #   # for c in range(cond_len): \n",
        "        #   _, decoder_hidden = self.decoder(latent_cond, decoder_hidden) \n",
        "\n",
        "        #   ### get outputs and hidden and cell state for rest of sequence\n",
        "        #   for s in range(seq_len): \n",
        "        #     if s==0: # first input is always the latent vector\n",
        "        #       decoder_input = z\n",
        "            \n",
        "        #     decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "        #     decoder_outputs[:,s] = decoder_output.squeeze(1)\n",
        "\n",
        "        #     if s<seq_len-1: # subsequent inputs. Don't need to get another input after last decoding\n",
        "        #       decoder_input = F.one_hot(torch.argmax(decoder_output,-1),latent_dim).type(torch.FloatTensor).to(self.device)\n",
        "\n",
        "        \n",
        "        # ###### or MIXED TEACHER FORCING within batch ...\n",
        "\n",
        "        # ### initialize output tensor\n",
        "        # decoder_outputs = torch.zeros((batch_size, seq_len, latent_dim), device=self.device)\n",
        "\n",
        "        # ### get hidden and cell state (but not output) for conditions\n",
        "        # # for c in range(cond_len): \n",
        "        # _, decoder_hidden = self.decoder(latent_cond, decoder_hidden) \n",
        "\n",
        "        # ### get outputs and hidden and cell state for rest of sequence\n",
        "        # for s in range(seq_len): \n",
        "        #   if s==0: # first input is always the latent vector\n",
        "        #     decoder_input = z\n",
        "        #   decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "        #   decoder_outputs[:,s] = decoder_output.squeeze(1)\n",
        "\n",
        "        #   if s<seq_len-1: # subsequent inputs. Don't need to get another input after last decoding\n",
        "        #     teacher_forcing = True if np.random.random() < teacher_forcing_ratio else False\n",
        "        #     if teacher_forcing:\n",
        "        #       decoder_input = x[:,s,:].unsqueeze(1)\n",
        "        #     else:\n",
        "        #       decoder_input = F.one_hot(torch.argmax(decoder_output,-1),latent_dim).type(torch.FloatTensor).to(self.device)\n",
        "        #       if not batch_idx%(50):\n",
        "        #         print(f'y: {torch.argmax(decoder_output.squeeze(1),-1)}')\n",
        "        #         print(f't: {torch.argmax(x[:,s,:],-1)}')\n",
        "\n",
        "\n",
        "        ###### ... end  \n",
        "\n",
        "        # x_hat = decoder_outputs[:,:,:input_height]\n",
        "        x_hat = self.fc_out(decoder_outputs)\n",
        "        # x_hat = self.softmax(x_hat)\n",
        "        # x_hat = decoder_outputs\n",
        "        if len(x_hat.shape)<3:\n",
        "          x_hat = x_hat.unsqueeze(0)\n",
        "\n",
        "\n",
        "        ###### LOSS ######  \n",
        "\n",
        "        ### calculate reconstruction loss  \n",
        "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
        "        # print(x_hat.shape,x.shape)\n",
        "        # recon_loss = self.loss(x_hat,x)\n",
        "        \n",
        "        ### calculate kl-divergence \n",
        "        if not vq:\n",
        "          kl = self.kl_divergence(z, mu, log_var)\n",
        "        # kl = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
        "\n",
        "        ### calculate proportion of incorrect predictions\n",
        "        arg_loss = ((torch.argmax(x,-1)-torch.argmax(x_hat,-1))**2).type(torch.FloatTensor)\n",
        "        arg_loss_mean = arg_loss.mean()\n",
        "        arg_loss_count = arg_loss.count_nonzero()/torch.numel(torch.argmax(x,-1))    \n",
        "\n",
        "        # ### increment beta\n",
        "        # if self.current_epoch >= 50 and self.beta <= 1: \n",
        "        #   self.beta+=10e-6 \n",
        "        \n",
        "        ### calculate elbo\n",
        "        if vq: \n",
        "          elbo = (vq_loss - recon_loss).mean()\n",
        "        else:\n",
        "          elbo = (self.beta*kl.mean() - (recon_loss)).mean()\n",
        "\n",
        "        ### gradient clipping \n",
        "        torch.nn.utils.clip_grad_norm_(self.parameters(), 0.25)\n",
        "\n",
        "\n",
        "        ###### LOGGING ###### \n",
        "\n",
        "        if not batch_idx%(20):\n",
        "          \n",
        "          # ### lightning logging\n",
        "          # self.log_dict({\n",
        "          #     'elbo': elbo,\n",
        "          #     'kl': kl.mean(),\n",
        "          #     'recon_loss': recon_loss.mean()\n",
        "          # })\n",
        "\n",
        "          ### print statements\n",
        "          print()\n",
        "          print(f'epoch: {self.current_epoch}, step: {self.global_step}')\n",
        "          if vq: \n",
        "            print(f'elbo: {elbo}, vq: {vq_loss.mean()}, recon: {recon_loss.mean()}')\n",
        "          else:\n",
        "            print(f'elbo: {elbo}, kl: {kl.mean()}, recon: {recon_loss.mean()}')\n",
        "          print(f'mean: {arg_loss_mean}, count: {arg_loss_count}, log scale: {self.log_scale.data}')\n",
        "          print(f'teacher forcing: {teacher_forcing}')\n",
        "          print(torch.argmax(x,-1)[:3])\n",
        "          if odd:\n",
        "            print(torch.tensor([[100 + x for x in range(num_conductors) for y in range(conductor_height)]]))\n",
        "          else:\n",
        "            print(torch.tensor([[100 + x for x in range(num_conductors_2) for y in range(conductor_2_height)]]))\n",
        "          print(torch.argmax(x_hat,-1)[:3])\n",
        "          \n",
        "          \n",
        "\n",
        "          ### weights and biases logging\n",
        "          if vq:\n",
        "            wandb.log({\n",
        "                'mean': arg_loss_mean, \n",
        "                'count': arg_loss_count, \n",
        "                'elbo': elbo,\n",
        "                'vq': vq_loss.mean(),\n",
        "                'recon_loss': recon_loss.mean(),\n",
        "                'log_scale': self.log_scale.data,\n",
        "                'beta': self.beta,\n",
        "                'epoch': self.current_epoch,\n",
        "                'step': self.global_step\n",
        "            })\n",
        "          else:\n",
        "              wandb.log({\n",
        "                'mean': arg_loss_mean, \n",
        "                'count': arg_loss_count, \n",
        "                'elbo': elbo,\n",
        "                'kl': kl.mean(),\n",
        "                'recon_loss': recon_loss.mean(),\n",
        "                'log_scale': self.log_scale.data,\n",
        "                'beta': self.beta,\n",
        "                'epoch': self.current_epoch,\n",
        "                'step': self.global_step\n",
        "            })\n",
        "        \n",
        "        \n",
        "        return elbo\n",
        "\n",
        "    def generate(self, condition=0):\n",
        "      with torch.inference_mode():\n",
        "\n",
        "        ### create condition       \n",
        "        cond = torch.zeros(1,1,latent_dim)\n",
        "        cond[:,:,condition]=1 # choose condition here\n",
        "        cond = cond.repeat(batch_size,1,1)\n",
        "\n",
        "        ### create random vector with zero mean and unit variance in shape of latent space\n",
        "        ex = torch.zeros(1,latent_dim)\n",
        "        p = torch.distributions.Normal(torch.zeros_like(ex), torch.ones_like(ex))\n",
        "        z = p.rsample((batch_size,))\n",
        "        decoder_input = z\n",
        "\n",
        "        ### initialize decoder\n",
        "        decoder_outputs = torch.zeros((batch_size, seq_len, latent_dim), device=self.device)\n",
        "        decoder_hidden = self.decoder.init_hidden()\n",
        "\n",
        "        ### NO TEACHER FORCING\n",
        "        _, decoder_hidden = self.decoder(cond, decoder_hidden)\n",
        "        for s in range(seq_len):\n",
        "          decoder_output, decoder_hidden = vae.decoder(decoder_input, decoder_hidden)\n",
        "          decoder_outputs[:,s] = decoder_output.squeeze(1)\n",
        "          decoder_input = F.one_hot(torch.argmax(decoder_output,-1),latent_dim).type(torch.FloatTensor).to(self.device)\n",
        "\n",
        "        ### get most likely notes greedily\n",
        "        pred = decoder_outputs.argmax(axis=-1)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gjk1abUgiUs"
      },
      "source": [
        "#### Other VAEs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SP-lelCQXE9"
      },
      "source": [
        "# class VQVAE(pl.LightningModule):\n",
        "#     def __init__(self, enc_out_dim=256, latent_dim=256, input_height=input_height):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.save_hyperparameters()\n",
        "        \n",
        "#         self.encoder = lstm_encoder(input_size=input_height, hidden_size=enc_out_dim)\n",
        "#         self.vq_vae = VectorQuantizerEMA(num_embeddings=128, embedding_dim=16, commitment_cost=0.25, decay=0.99)\n",
        "#         # self.vq_vae = VectorQuantizer(num_embeddings=128, embedding_dim=16, commitment_cost=0.25)\n",
        "#         self.decoder = lstm_decoder(input_size=input_height, hidden_size=latent_dim)\n",
        "\n",
        "#         self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
        "#         self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
        "\n",
        "#         # for the gaussian likelihood\n",
        "#         self.log_scale = nn.Parameter(torch.Tensor([-2.6]))\n",
        "\n",
        "#     def configure_optimizers(self):\n",
        "#         return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "#     def reparameterize(self, mu, logvar):\n",
        "#         std = torch.exp(0.5 * logvar)\n",
        "#         eps = torch.randn_like(std)\n",
        "#         return (eps * std) + mu\n",
        "\n",
        "#     def gaussian_likelihood(self, mean, logscale, sample):\n",
        "#         scale = torch.exp(logscale)\n",
        "#         dist = torch.distributions.Normal(mean, scale)\n",
        "#         log_pxz = dist.log_prob(sample)\n",
        "#         # return log_pxz.sum()\n",
        "#         return log_pxz.mean()\n",
        "\n",
        "#     def training_step(self, batch, batch_idx):\n",
        "#         x = batch\n",
        "\n",
        "#         # encoder_hidden = self.encoder.init_hidden(batch_size)\n",
        "#         # z, encoder_hidden = self.encoder(x,encoder_hidden)\n",
        "#         z, _ = self.encoder(x)\n",
        "#         # z = z.unsqueeze(1)\n",
        "#         # z = z.repeat(1,100,1)\n",
        "    \n",
        "#         vq_loss, quantized, perplexity, _ = self.vq_vae(z)\n",
        "#         # quantized = z\n",
        "\n",
        "#         # get latent space\n",
        "#         # mu, log_var = self.fc_mu(z), self.fc_var(z)\n",
        "#         # quantized = self.reparameterize(mu, log_var)\n",
        "#         quantized = quantized.unsqueeze(1)\n",
        "#         quantized = quantized.repeat(1,100,1)\n",
        "#         # print(quantized[0]==quantized[1])\n",
        "\n",
        "#         # decoder_hidden = self.decoder.init_hidden(batch_size)\n",
        "#         # print(decoder_hidden[0].shape, quantized.shape)\n",
        "#         # x_recon, decoder_hidden = self.decoder(quantized,decoder_hidden)\n",
        "#         x_recon, _ = self.decoder(quantized)\n",
        "#         # print(x.shape,x_recon.shape)\n",
        "#         # print(x_recon[0]==x_recon[1])\n",
        "#         # print(x.shape,z.shape,quantized.shape,x_recon.shape)\n",
        "\n",
        "#         # bce = nn.BCELoss()\n",
        "#         # recon_error = F.mse_loss(x_recon, x)\n",
        "#         # recon_error = bce(x_recon, x)\n",
        "#         recon_error = self.gaussian_likelihood(x_recon, self.log_scale, x)\n",
        "#         loss = recon_error - vq_loss\n",
        "#         # loss = recon_error\n",
        "#         loss = -loss.mean()\n",
        "\n",
        "        \n",
        "\n",
        "#         # number of correct predictions\n",
        "#         # arg_loss = ((torch.argmax(x.squeeze(),-1)-torch.argmax(x_recon,-1))**2).type(torch.FloatTensor)\n",
        "#         arg_loss = ((torch.argmax(x,-1)-torch.argmax(x_recon,-1))**2).type(torch.FloatTensor)\n",
        "#         arg_loss_mean = arg_loss.mean()\n",
        "#         # arg_loss_count = arg_loss.count_nonzero()/torch.numel(torch.argmax(x.squeeze(),-1))\n",
        "#         arg_loss_count = arg_loss.count_nonzero()/torch.numel(torch.argmax(x,-1))        \n",
        "\n",
        "#         if not batch_idx%(50):\n",
        "#           print(batch_idx, loss, vq_loss, recon_error)\n",
        "#           print(torch.argmax(x,-1)[:3])\n",
        "#           print(torch.argmax(x_recon,-1)[:3])\n",
        "#           print(f'mean: {arg_loss_mean}, count: {arg_loss_count}, log scale: {self.log_scale.data}')\n",
        "\n",
        "#           wandb.log({\n",
        "#               'mean': arg_loss_mean, \n",
        "#               'count': arg_loss_count, \n",
        "#               'loss': loss, \n",
        "#               'recon': recon_error,\n",
        "#               'vq': vq_loss,\n",
        "#               'epoch': self.current_epoch,\n",
        "#               'step': self.global_step\n",
        "#           })\n",
        "\n",
        "#         return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmKoBsq5_bk8"
      },
      "source": [
        "# class VAE(pl.LightningModule):\n",
        "#     def __init__(self, input_dim=input_height, hidden_dim=88, latent_dim=88):\n",
        "#         super().__init__()\n",
        "        \n",
        "#         self.beta=1\n",
        "#         # self.beta = 1\n",
        "#         self.save_hyperparameters()\n",
        "\n",
        "#         # encoder, decoder\n",
        "#         self.encoder = lstm_encoder(input_size=input_dim, hidden_size=hidden_dim, output_size=hidden_dim, batch_size=batch_size)\n",
        "#         self.decoder = lstm_decoder(input_size=latent_dim, hidden_size=hidden_dim, output_size=input_dim, batch_size=batch_size)\n",
        "\n",
        "#         # distribution parameters\n",
        "#         self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "#         self.fc_var = nn.Linear(hidden_dim, latent_dim)\n",
        "#         # self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
        "#         # self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
        "\n",
        "#         # for the gaussian likelihood\n",
        "#         # self.log_scale = nn.Parameter(torch.Tensor([-2]))\n",
        "#         self.log_scale = nn.Parameter(torch.Tensor([-2.6]))\n",
        "\n",
        "#     def configure_optimizers(self):\n",
        "#         return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "#     def gaussian_likelihood(self, mean, logscale, sample):\n",
        "#         scale = torch.exp(logscale)\n",
        "#         dist = torch.distributions.Normal(mean, scale)\n",
        "#         log_pxz = dist.log_prob(sample)\n",
        "#         # return log_pxz.sum()\n",
        "#         return log_pxz.mean()\n",
        "\n",
        "#     def reparameterize(self, mu, logvar):\n",
        "#         std = torch.exp(0.5 * logvar)\n",
        "#         eps = torch.randn_like(std)\n",
        "#         return (eps * std) + mu\n",
        "\n",
        "#     def kl_divergence(self, z, mu, log_var):\n",
        "\n",
        "#         std = torch.exp(log_var / 2)\n",
        "\n",
        "#         p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
        "#         q = torch.distributions.Normal(mu, std)\n",
        "\n",
        "#         log_qzx = q.log_prob(z)\n",
        "#         log_pz = p.log_prob(z)\n",
        "\n",
        "#         kl = (log_qzx - log_pz)\n",
        "#         kl = kl.mean(-1)\n",
        "#         return kl\n",
        "        \n",
        "\n",
        "#     def training_step(self, batch, batch_idx):\n",
        "        \n",
        "#         # separate all data and conditional\n",
        "#         x, cond = batch \n",
        "#         # x = batch\n",
        "#         # print(x.shape)\n",
        "\n",
        "#         # encode x to get the mu and variance parameters\n",
        "#         encoder_hidden = self.encoder.init_hidden()\n",
        "#         x_encoded, encoder_hidden = self.encoder(x, encoder_hidden)\n",
        "#         # x_encoded,_ = self.encoder(x)\n",
        "\n",
        "#         # x_out = encoder_hidden[0].transpose(0,1)\n",
        "#         x_encoded = x_encoded[:,1:,:]\n",
        "#         # get latent space\n",
        "#         mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
        "#         # mu, log_var = self.fc_mu(x_out), self.fc_var(x_out)\n",
        "#         z = self.reparameterize(mu, log_var)\n",
        "        \n",
        "\n",
        "#         kl = self.kl_divergence(z, mu, log_var)\n",
        "\n",
        "#         # recondition latent space\n",
        "#         z = torch.cat((cond,z),1)\n",
        "\n",
        "#         # z = x_encoded\n",
        "\n",
        "#         # decoded \n",
        "#         decoder_hidden = self.decoder.init_hidden()\n",
        "#         x_hat, decoder_hidden = self.decoder(z, decoder_hidden)\n",
        "#         # x_hat,_ = vae.decoder(z)\n",
        "\n",
        "#         # reconstruction loss\n",
        "#         # recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x[:,:,:-10])\n",
        "#         recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
        "        \n",
        "#         # kl\n",
        "#         # kl = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
        "#         # kl=0\n",
        "\n",
        "#         # number of correct predictions\n",
        "#         arg_loss = ((torch.argmax(x.squeeze(),-1)-torch.argmax(x_hat,-1))**2).type(torch.FloatTensor)\n",
        "#         arg_loss_mean = arg_loss.mean()\n",
        "#         arg_loss_count = arg_loss.count_nonzero()/torch.numel(torch.argmax(x.squeeze(),-1))     \n",
        "        \n",
        "#         # elbo\n",
        "        \n",
        "#         # if self.current_epoch >= 1 and self.beta <= 1: \n",
        "#         #   self.beta+=10e-6\n",
        "#         # elbo = (self.beta*kl - (recon_loss)) + arg_loss_count\n",
        "#         elbo = (self.beta*kl - (recon_loss))\n",
        "#         # elbo =  - (recon_loss)\n",
        "#         elbo = elbo.mean()\n",
        "\n",
        "#         # # logging\n",
        "#         # self.log_dict({\n",
        "#         #     'elbo': elbo,\n",
        "#         #     'kl': kl.mean(),\n",
        "#         #     'recon_loss': recon_loss.mean()\n",
        "#         # })\n",
        "\n",
        "#         # gradient clipping \n",
        "#         torch.nn.utils.clip_grad_norm_(self.parameters(), 0.25)\n",
        "\n",
        "#         # print statements\n",
        "#         if not batch_idx%(50):\n",
        "#           print()\n",
        "#           print(batch_idx, elbo, kl.mean(), recon_loss.mean())\n",
        "#           print(torch.argmax(x.squeeze(),-1)[:3])\n",
        "#           print(torch.argmax(x_hat,-1)[:3])\n",
        "#           # print(_[0].shape,_[1].shape)\n",
        "#           # print(torch.max(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1),-1)[:3])\n",
        "#           # print(torch.min(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1),-1)[:3])\n",
        "#           print(f'mean: {arg_loss_mean}, count: {arg_loss_count}, log scale: {self.log_scale.data}')\n",
        "#           print(f'epoch: {self.current_epoch}, step: {self.global_step}')\n",
        "#           wandb.log({\n",
        "#               'mean': arg_loss_mean, \n",
        "#               'count': arg_loss_count, \n",
        "#               'elbo': elbo,\n",
        "#               'kl': kl.mean(),\n",
        "#               'recon_loss': recon_loss.mean(),\n",
        "#               'log_scale': self.log_scale.data,\n",
        "#               'beta': self.beta,\n",
        "#               'epoch': self.current_epoch,\n",
        "#               'step': self.global_step\n",
        "#           })\n",
        "        \n",
        "        \n",
        "#         return elbo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQYoxfnzgr0Q"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "piYEFZQXInao",
        "outputId": "ac137aa4-e854-4b97-9cce-b7b02a050f9c"
      },
      "source": [
        "wandb.init(project=\"piano_generation\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/tashinam/piano_generation/runs/2t8xe9wn\" target=\"_blank\">worldly-grass-368</a></strong> to <a href=\"https://wandb.ai/tashinam/piano_generation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f177537d150>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/tashinam/piano_generation/runs/2t8xe9wn?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e5dd2e5c29d64e37a62ea8f2aa349397",
            "af9487df39c8411ca1ebd308dcdc76bc",
            "73176dcd180e4124980ab1c56bd45222",
            "1c6268854aa1467b9e1ad679198c742f",
            "11ae5dd836d14db993c65a904487dc05",
            "09e59be383fe45839d5138981b082d40",
            "09c0ae9775fd44b3a963a32b1dee2165",
            "3292764e9f7a4e8aa249108ea8697686",
            "91e6591742af4c9d8641f41794c6c2ad",
            "8b2e59f50d4643fc850c79a7cab9a004",
            "7eb0621d38524a838965473ff5ae7cd8"
          ]
        },
        "id": "uhVk_qZImPFW",
        "outputId": "3df34163-c320-461a-ba13-b3bc904534de"
      },
      "source": [
        "# checkpoint_callback = ModelCheckpoint(every_n_train_steps=1000)\n",
        "torch.set_printoptions(linewidth=1000)\n",
        "teacher_forcing_ratio=0\n",
        "batch_size = 128\n",
        "vq=False\n",
        "vae = VAE()\n",
        "# trainer = pl.Trainer(gpus=1, max_epochs=100, callbacks=[checkpoint_callback], default_root_dir='/content/drive/MyDrive/Colab Notebooks/piano_generation/models')\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=100, default_root_dir='/content/drive/MyDrive/Colab Notebooks/piano_generation/models')\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# data = Maestro('/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/mido_100_short_combined.csv', '/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/mido_100_short_classes.csv')\n",
        "# data = Maestro('/content/drive/MyDrive/Colab Notebooks/piano_generation/16_seqs.csv', '/content/drive/MyDrive/Colab Notebooks/piano_generation/16_conditions.csv')\n",
        "# data = Maestro('/content/drive/MyDrive/Colab Notebooks/piano_generation/16_seqs.csv')\n",
        "data = Maestro('/content/drive/MyDrive/Colab Notebooks/piano_generation/100_seqs.csv',input_height=input_height)\n",
        "loader = DataLoader(data, batch_size=batch_size, num_workers=os.cpu_count(),drop_last=True,shuffle=True)\n",
        "trainer.fit(vae, loader)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla P100-PCIE-16GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name        | Type           | Params\n",
            "-----------------------------------------------\n",
            "0 | encoder     | lstm_encoder   | 2.3 M \n",
            "1 | conductor   | lstm_conductor | 1.2 M \n",
            "2 | conductor_2 | lstm_conductor | 1.2 M \n",
            "3 | decoder     | lstm_decoder   | 1.2 M \n",
            "4 | fc_mu       | Linear         | 131 K \n",
            "5 | fc_var      | Linear         | 131 K \n",
            "6 | fc_out      | Linear         | 22.6 K\n",
            "-----------------------------------------------\n",
            "6.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "6.1 M     Total params\n",
            "24.491    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5dd2e5c29d64e37a62ea8f2aa349397",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 0, step: 0\n",
            "elbo: -0.5445136427879333, kl: 0.00062556256307289, recon: 0.5445137023925781\n",
            "mean: 98.6987533569336, count: 1.0, log scale: tensor([-2.6000], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 0,  0,  0, 11, 11, 10,  2,  7,  6, 10,  5,  1,  1,  1,  2,  8,  1,  1,  7,  3,  0,  2,  8,  5,  6,  6,  7,  3,  4,  4,  3,  3,  5,  6,  6, 12,  6,  5,  6, 11,  8,  2, 14,  6,  6,  5,  0,  2,  4,  4, 12, 11, 11, 10,  4,  1,  2, 12,  5,  5,  6,  9, 13, 14, 14,  4,  0,  1,  1,  1,  1,  6, 10, 10, 11, 14, 14,  3, 10, 14, 10, 11,  5,  5,  8,  0, 14, 10,  6,  6, 12,  3, 13,  9,  8, 12,  8,  2,  6,  5],\n",
            "        [ 7, 13, 13, 14, 11, 14, 14,  6,  7, 14, 11,  9, 13,  9,  6,  7,  7, 12,  5,  5,  6,  7,  3, 10, 11,  7,  6,  3,  8,  7,  7,  7,  0,  1,  5,  4, 11,  6, 13,  3,  8, 12,  9,  5,  1, 14,  2,  3, 10, 11,  7,  9,  5,  1,  0,  7, 14, 14, 13,  9, 10,  6,  7,  2,  6,  3,  4,  3,  3,  3,  4, 11,  6, 14, 14, 10, 12,  5,  3,  8,  9,  8,  9,  2,  6,  7,  8, 10, 13,  9,  2,  4,  2,  2,  4,  4,  9,  8,  4,  8],\n",
            "        [13, 12,  9,  8,  5,  9,  2,  5,  5,  6, 14,  4, 13, 13, 13,  9, 13, 11,  7,  7,  3,  7, 12,  9,  9, 12,  9, 13, 14,  7, 14,  8,  9,  7,  8,  8,  9,  8,  1,  4,  8,  1,  8,  1,  0,  1,  8,  3, 10, 11, 10,  2,  9,  8,  7, 14,  7, 11, 10,  9, 10, 10, 11, 11, 14, 14,  0,  1,  4,  6,  4,  8,  8, 12, 12, 13, 14, 13,  9,  8, 12, 13, 13, 13, 11,  5,  2,  7,  7, 10,  4, 11, 12,  8,  1,  1,  0,  0,  8, 10]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 20\n",
            "elbo: -0.7366240620613098, kl: 0.0013103466480970383, recon: 0.7366241812705994\n",
            "mean: 19.972108840942383, count: 0.9293749928474426, log scale: tensor([-2.5806], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 4,  4,  0,  0,  1,  8,  3,  4,  4,  5,  5,  3,  2,  7, 14, 10,  1,  8, 14,  5,  1,  1,  0,  7,  9, 13, 13, 13, 12, 10,  1,  1,  0,  1,  0,  3,  6,  6, 10, 11,  6, 11, 10, 14, 10, 12, 12,  9, 12,  6,  3, 10, 10, 14,  0,  7,  6, 11, 11,  7, 11, 12, 11, 14, 14, 12, 11, 11, 10,  6,  7, 14, 10, 10, 10, 14,  7, 10,  1,  0, 14, 12, 11,  3,  7,  7,  3,  7,  1,  2,  5, 10, 11,  8,  9,  0,  1, 13, 12, 13],\n",
            "        [ 2,  8,  4,  5,  5,  6,  6,  6,  6,  2,  2, 12,  6,  1,  1,  5,  9,  8,  5,  5, 10, 10, 11,  5,  1,  5,  3, 10, 11,  0,  2,  9, 13,  7,  1,  8, 10,  9,  6,  6, 10, 14,  8,  1, 10, 10, 11,  7, 10, 13,  0,  1,  0,  0,  0,  4,  6,  7,  1, 12, 13,  9,  6,  9,  0,  1,  4, 11,  9,  8,  1,  7,  8,  8, 12,  5,  6,  2,  6,  9,  2,  1,  1,  5,  5,  5, 11, 12, 12, 12, 12,  9, 12,  8, 12, 10, 11, 14,  7,  8],\n",
            "        [ 1,  8,  0,  7,  1,  0,  1,  8,  7,  5,  6,  6, 13, 10,  9,  6,  9,  8,  9,  8,  6, 11,  7, 10,  7,  0,  4, 11, 14,  7, 10,  9,  8, 12, 11,  3,  7,  6, 10, 13, 12, 12, 14, 13,  1,  2,  1,  1,  2,  2,  1, 10,  4,  1,  0,  7, 14, 14, 11,  5,  9,  9,  1,  0,  4,  5,  6,  7,  8,  4,  7,  6, 12, 11, 10,  7,  3,  6,  9,  6,  8,  9,  5, 12, 11, 14, 10, 11, 10, 13, 11, 10,  6,  7,  8,  3,  8,  9, 10,  6]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[ 7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  7,  9,  7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  7, 10, 10,  9,  9, 10, 10, 10,  9,  9, 10, 10, 10,  9,  9, 10, 10, 10,  9,  9],\n",
            "        [ 7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  7, 10, 10,  9,  9, 10, 10, 10,  9,  9, 10, 10, 10,  9,  9, 10, 10, 10,  9,  9],\n",
            "        [ 7,  7,  7,  7,  9,  9,  7,  7,  7,  9,  9,  7,  7,  7,  9,  9,  7,  7,  7,  9,  7,  7,  7,  7,  9,  9,  7,  7,  7,  9,  9,  7,  7,  7,  9,  9,  7,  7,  7,  9,  7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  7,  9,  7,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  9,  7,  7,  9,  9,  7, 10, 10,  9,  9, 10, 10, 10,  9,  9, 10, 10, 10,  9,  9, 10, 10, 10,  9,  9]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 40\n",
            "elbo: -0.7528734803199768, kl: 0.0026268765795975924, recon: 0.7528737187385559\n",
            "mean: 22.341014862060547, count: 0.9214062690734863, log scale: tensor([-2.5617], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 7,  7,  2,  2,  8, 13,  6,  7,  7,  6,  7,  6,  6,  6,  2,  1,  2,  1,  0,  0,  4, 11,  2,  2,  4,  8, 13,  9, 12, 11, 12, 12, 12, 13,  9,  1,  2, 12,  6, 12,  2,  1,  0,  0,  4, 11, 14, 13,  1,  1,  8,  8,  9, 10, 12, 11, 11, 10, 14, 14,  0,  4,  3,  9,  7,  5,  5,  0,  9,  9,  5,  7,  6,  6, 10, 12,  6,  7,  6,  2,  4,  4, 13, 10, 11, 10,  1,  5,  9,  9,  2,  6,  6,  5,  7,  2,  3,  2,  2,  8],\n",
            "        [13, 14,  1,  0,  0,  3,  3,  6,  5, 11, 11,  8,  7, 11, 10,  9,  5,  6,  6,  2,  9, 11,  5,  6,  6,  7,  0,  1,  5,  6,  2,  2,  1,  1,  3,  7,  5,  5,  5,  6,  6,  5, 12,  5,  6,  2,  2,  3,  9,  6,  5,  4, 13, 14, 10, 11,  4, 14, 13, 13,  9, 13,  3,  3, 12, 13,  7,  6,  5,  4,  4, 11, 14, 10,  5,  1,  6,  6,  3, 14,  8,  9, 10, 11,  4, 10,  5,  4,  0,  3,  2,  1,  4,  4,  2,  4,  4,  3,  3,  2],\n",
            "        [ 7,  9, 13, 12, 12, 13, 10,  7, 12,  5,  0,  7, 11, 10, 14, 13, 12,  9,  8, 12,  9,  9,  5,  6, 10,  7,  8,  9,  6,  6,  7,  6,  2, 13, 13, 12, 10, 12,  7,  7, 10,  8,  3,  4,  8,  9,  3,  2,  4,  0,  7, 11, 14, 13,  2,  2,  2,  2,  1,  7,  6,  6,  5,  5, 13, 14, 14, 13, 13, 14, 13, 13,  9,  9,  9,  9,  5,  4,  7, 11, 14,  7,  2,  5, 11, 11, 10,  9, 10,  9,  5,  3,  2,  6,  9,  9,  5,  8, 10,  3]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[ 7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7,  7, 10, 10,  7,  7,  7, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  4, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10],\n",
            "        [ 7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7,  7, 10, 10,  7,  4, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  4, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  4, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10],\n",
            "        [ 7,  4, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  4, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  4, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 60\n",
            "elbo: -0.7667314410209656, kl: 0.007247681729495525, recon: 0.7667321562767029\n",
            "mean: 16.99820327758789, count: 0.9229687452316284, log scale: tensor([-2.5434], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 3,  6,  5,  9,  8, 13,  6,  9, 10, 11, 13, 11, 11, 12, 11,  8,  5,  9,  9, 12, 13,  9,  6,  2,  3, 10,  8,  0,  0,  1,  5,  6,  7,  7,  5,  5,  3,  6,  4,  4,  6, 11,  7,  6, 10,  7, 11, 14, 14, 12, 11, 14, 14,  4,  4,  6,  2,  6,  7, 10, 11,  8,  8,  8, 12, 12,  8,  8, 11, 11,  4, 13, 11, 11, 12, 13,  1,  5,  1,  2, 11, 11, 10, 13,  5, 12, 13,  7,  6, 10,  9,  8,  9,  4,  5,  7,  9,  7,  6,  6],\n",
            "        [ 0,  5,  5,  6,  2, 12, 12, 12,  0,  3,  9,  2,  9,  8,  1,  5, 11,  8,  8,  8,  3,  0,  5,  9,  6,  5, 14,  0,  4, 10, 11, 11,  9,  8, 14,  9, 11,  7,  7,  7,  0,  3,  5,  4,  3,  3, 10, 11, 10, 10,  7, 14, 14,  7, 13, 11, 11, 11, 13,  8,  1,  8,  1, 13, 12, 13, 14,  3,  8, 14, 13, 12,  8, 11, 10, 13,  4,  4,  8,  1,  8, 10, 14, 11,  7,  1,  3,  4,  5, 10, 11, 12, 13, 12, 13,  2,  3,  3, 14, 12],\n",
            "        [ 0,  1,  5, 12, 11,  7,  7,  2,  2,  7, 12, 12, 14, 14, 10, 11, 13, 12,  1, 12, 14, 12,  6,  0,  7,  8,  9,  5,  1,  2,  6,  4,  5,  8, 12,  3,  3,  4, 11,  8,  5,  4,  8,  9,  7,  8,  8, 13, 12, 11,  4, 14,  9,  3,  4,  4,  8, 12, 13, 14, 11,  8,  5,  5, 12,  5,  7,  2,  1,  1,  6,  7,  8, 10,  9, 14, 13,  9,  9, 10, 13, 13,  9, 12,  6, 11,  4,  6,  3,  9, 13, 12, 12, 12, 13, 13,  4,  0,  0,  0]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
            "        [7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
            "        [7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 80\n",
            "elbo: -0.7788805961608887, kl: 0.03386584669351578, recon: 0.7788839936256409\n",
            "mean: 20.68390655517578, count: 0.9219531416893005, log scale: tensor([-2.5258], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 3,  3, 14, 12, 11, 12, 12,  8,  9,  4, 12, 12,  9,  9,  5, 12, 11, 12, 14, 10, 13,  6,  7,  1,  4, 11, 14, 13,  6,  8,  5,  8,  9,  2, 14, 13,  7,  8,  8, 12, 12,  7,  8,  9, 13,  2,  3,  6,  5, 12,  7,  6,  5,  4,  3,  7, 10, 14, 14,  8, 14,  0,  1, 13,  3,  3,  7,  7,  2, 14,  7,  7,  7,  5,  0,  1,  0,  1,  5,  8,  9,  2,  8,  1,  1,  6,  6,  5,  5,  5,  9,  7,  8,  4, 11, 10, 10,  4, 11, 10],\n",
            "        [ 3,  4,  8, 13, 10, 11,  6,  2,  5,  5,  8,  4,  5, 14, 10,  6, 14,  5, 12, 13, 13, 13, 13,  9, 12, 12, 12,  8,  7,  7,  9, 10, 12, 11, 12,  9,  6,  9,  9,  5,  5, 10,  6,  9,  5,  2,  8,  5,  3,  4, 11, 10,  4, 13,  1,  2,  8,  7, 11,  9,  8, 14,  7,  9, 10,  6,  1,  1,  8,  8,  1,  2,  6,  9,  2,  2, 10,  9,  6,  5, 10,  8, 13, 12, 13, 14, 14, 10,  0, 14, 14, 10, 11, 12, 13,  2,  0,  4,  4,  2],\n",
            "        [ 4,  4,  9,  3, 10, 10,  7, 12, 11, 10,  7,  3, 14, 11, 14,  4,  1,  9,  5,  6, 10,  3,  3, 13, 10,  0, 11,  8,  6, 11, 10, 13, 14,  5,  5,  6,  0,  7,  6,  3,  2, 11, 12, 11,  6, 14,  9, 10,  8,  8, 11, 13, 12, 12,  1,  2,  0,  3,  4,  7, 13, 10, 11, 11,  5,  5, 11, 12, 10, 13, 13,  5,  2,  1,  5,  3,  2, 10, 14, 11, 10,  9,  9,  3,  2,  1,  1,  5,  6,  7, 12,  5, 13, 14, 11, 14, 11, 12, 11, 11]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[7, 7, 7, 5, 5, 7, 7, 7, 5, 5, 8, 7, 7, 5, 5, 8, 7, 7, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5],\n",
            "        [7, 7, 7, 5, 5, 7, 7, 7, 5, 5, 7, 7, 7, 5, 5, 7, 7, 7, 5, 5, 7, 7, 7, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 7, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5],\n",
            "        [4, 4, 5, 5, 5, 4, 4, 5, 5, 5, 4, 4, 5, 5, 5, 4, 4, 5, 5, 5, 4, 7, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 100\n",
            "elbo: -0.790622889995575, kl: 0.08194182068109512, recon: 0.7906310558319092\n",
            "mean: 19.78695297241211, count: 0.9240624904632568, log scale: tensor([-2.5091], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 0,  1,  0,  2,  1,  2,  7,  6,  5,  5, 11, 11,  4,  6, 13,  3,  7,  8,  9,  9, 10,  9,  8,  7, 12, 13, 12,  5, 12,  9,  8,  9, 13, 14,  1,  1,  4, 11, 14, 10, 10,  3,  4,  5,  2,  5,  4, 11,  4,  5,  1,  5,  8,  4,  8,  9, 12, 12, 13, 14,  9,  5,  5,  6,  2,  6,  5,  7, 11, 10, 10, 14,  0, 13,  5,  0,  8,  1,  1,  5, 13,  8, 10,  9, 13,  0,  5, 13,  6,  6,  6, 13,  5,  5,  6,  4,  5,  5,  9,  6],\n",
            "        [14, 14, 14, 11, 11, 10, 13,  3,  2,  0,  0,  1,  0,  4,  5,  6, 14,  0,  7, 14, 13,  1,  1,  5,  5,  6,  9, 13, 12, 13, 14,  5,  9, 14,  7,  4,  0, 14,  3,  7, 11,  8, 13, 14,  0,  7,  7,  6,  7,  7,  0,  3,  8,  7,  8, 11, 10,  4,  6, 10,  9, 14,  7,  5, 10, 12,  9,  9, 14, 11, 11,  7,  9, 10, 14, 10,  9,  9,  9, 11, 10,  9,  9,  5, 12, 12,  5, 10,  3,  3,  3,  7, 11, 14, 14,  1,  1,  2,  9,  0],\n",
            "        [ 3,  2,  1,  8,  9,  8,  4,  5,  3,  7,  6,  8, 12, 11,  4,  2,  5,  5,  6,  6,  0, 13, 10,  9, 10, 14,  0,  7,  5,  6, 13,  9,  8,  5,  6,  7, 11, 12,  8,  8, 14, 11, 10,  9,  9,  9, 11, 11,  5,  5,  6, 11, 10,  6,  0, 14,  9, 10, 13, 13, 14, 12, 13, 13,  3,  1,  1, 11, 10, 13, 10,  1,  2,  6,  1,  0,  1,  0,  3,  3, 12,  4,  8,  5,  4,  5,  8,  7, 13,  8, 11, 14, 11, 12,  8,  8,  4,  3, 10,  0]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[ 0,  0,  4,  4,  4,  0,  4,  4,  4,  4,  1,  4,  4,  4,  4,  0,  4,  4,  4,  4,  4,  4,  4,  4,  7,  4,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7,  7, 10,  7,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 10,  7,  7,  7,  7, 10, 10,  7,  7,  7, 10, 10, 10,  7,  7,  7,  7,  7,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7,  7,  7,  7,  7,  7, 10, 10,  7,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 0,  4,  4,  4,  4,  0,  4,  4,  4,  4,  7,  4,  4,  4,  4,  7,  4,  4,  4,  4,  7,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 10, 10,  7,  7,  7,  7,  7,  7,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7,  7,  7,  7,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7, 10, 10, 10,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 120\n",
            "elbo: -0.8003384470939636, kl: 0.21007370948791504, recon: 0.8003594279289246\n",
            "mean: 24.293907165527344, count: 0.9220312237739563, log scale: tensor([-2.4931], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 0,  0,  1,  8,  1,  4, 11,  8,  4, 13, 11, 12, 14,  2,  8,  9, 10, 10,  9, 10, 14, 11, 12, 10,  8,  8, 13,  7,  3, 13, 12, 13, 12, 13,  6,  9, 11,  5,  6, 10,  9,  6, 12, 13, 12, 11,  4,  5,  6,  8,  8,  3,  7,  7,  1,  0,  0,  3,  3, 12, 12, 10,  1, 13, 12,  8,  5,  4,  5,  9,  3,  3,  9,  2,  4,  3,  3,  3,  0, 12, 12, 13,  7, 11, 12,  9, 13, 13, 14,  7, 11, 10, 14, 10, 10, 10, 11, 11, 12, 10],\n",
            "        [ 4,  5,  9,  8,  0, 14, 12,  1,  4,  3,  3,  3,  6,  2,  4,  3,  6,  5, 14, 14,  8,  4,  3,  9, 11,  3,  3,  0, 14, 11, 10, 10,  0,  1, 11, 11,  6,  4,  3,  0,  0, 10,  9,  9, 11,  4,  4, 11,  0,  3,  5, 12, 12,  6,  7,  6,  1, 11, 11, 12,  6,  6, 12,  1,  0,  2,  1, 11,  8,  6,  7, 13,  7,  0,  0,  1,  2,  2,  6,  8, 14, 12,  5,  4,  0,  7, 12,  9,  8, 13, 13, 12, 14, 14, 14, 11,  0,  1,  2, 14],\n",
            "        [ 0,  7,  6, 10, 10,  3,  5, 10,  3,  3,  1,  0,  0, 14, 14, 10, 11,  6,  2,  4,  5,  6, 10, 10, 10, 11, 10, 14,  8,  3,  3,  3, 10,  9,  8,  5, 10, 12, 12,  5,  7,  3,  9,  5,  5,  4,  6,  5, 14, 11, 11,  7,  6,  6,  6,  6, 14, 12,  9, 12,  8, 13,  9, 10, 12, 10,  7,  9, 10, 14, 13, 13, 12,  3,  9,  9,  5,  6,  5,  3,  1,  4,  5,  1,  5,  1,  5,  1,  7,  7,  9,  2,  6,  5,  4,  1,  2,  1,  7, 13]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[0, 0, 1, 1, 1, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 7, 7, 9, 9, 9, 7, 7, 9, 9, 9, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 7, 9, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 4, 4, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5],\n",
            "        [0, 1, 1, 4, 4, 1, 1, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 1, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5],\n",
            "        [0, 1, 1, 1, 1, 1, 1, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 7, 4, 4, 4, 5, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 140\n",
            "elbo: -0.8078830242156982, kl: 0.11302992701530457, recon: 0.8078943490982056\n",
            "mean: 17.52554702758789, count: 0.9165624976158142, log scale: tensor([-2.4779], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 0,  6, 13, 13, 12, 12, 13,  9,  9, 13, 14, 13, 12, 14, 10, 14, 13, 14, 13,  9,  2,  3,  0,  0,  7, 13, 10,  3,  3,  7, 11, 11,  4,  1,  5,  5,  6,  0,  3,  3,  3,  3,  4,  5,  2,  6,  0,  3,  2,  6, 13, 13, 12, 12, 13, 10, 10, 11, 11, 14, 13, 13, 13, 14, 13, 14,  7,  9,  9,  1,  0,  7, 14,  9, 14, 13,  9, 10, 11,  7,  1,  2,  4,  3,  4, 11,  4,  8,  6, 10,  4,  4, 11,  4,  5,  9,  4,  3,  4,  1],\n",
            "        [ 4,  3,  3,  6,  6, 12,  5,  4,  7,  6,  6,  7,  7,  8, 10, 10, 12, 12, 12, 11, 10, 11, 11,  4, 11, 10, 13, 12, 13, 13,  7,  7,  3,  8, 13, 13, 14, 14,  7, 14, 14, 13, 14, 10, 14,  9, 10,  3,  4, 14, 13, 14, 11, 10,  3,  4,  3,  2,  8, 14,  5,  9, 10, 11, 11, 11,  3,  7,  7, 11, 12, 11,  0,  4,  3, 13,  7,  0,  2,  9, 13, 14, 14, 10,  8,  4,  8,  4, 10,  5,  5, 12,  8,  9,  7,  0,  1,  1,  7,  6],\n",
            "        [ 4,  3,  7,  8,  7,  3, 10, 11, 11,  4, 11,  4,  5,  5,  5,  4, 11, 11,  6,  4,  5,  5,  9,  8,  7,  7,  8, 12, 11, 14, 14, 11, 10,  9, 10, 11,  8,  3, 10, 14, 13,  9,  9,  9,  6,  8,  6,  5,  9,  2,  5,  1,  4,  4,  1,  4, 11, 11,  1,  4,  4,  4,  5,  6,  7, 13,  9,  0,  9, 10,  9,  1, 11, 11, 11, 12, 12, 13, 13, 14, 10,  8,  4,  5, 12,  5, 11, 14,  7, 11, 10, 13, 12,  2,  4,  4, 11,  0,  7, 11]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[0, 0, 0, 0, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 7, 5, 7, 7, 7, 7, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7],\n",
            "        [0, 4, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7],\n",
            "        [1, 4, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 160\n",
            "elbo: -0.8154584169387817, kl: 0.17755797505378723, recon: 0.8154761791229248\n",
            "mean: 16.666719436645508, count: 0.9190624952316284, log scale: tensor([-2.4635], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 7, 11, 11,  3,  3,  9, 10, 10, 10,  6,  5,  6,  1,  1,  8,  1,  2,  7,  6,  4,  3,  9, 11, 11, 11, 10, 10, 11, 10, 14, 12,  5,  3,  6,  6,  5,  9, 12,  5,  6,  6,  7,  4,  4, 11,  4,  4,  6,  6,  9,  6,  4,  1,  5,  1,  5,  8,  4,  1,  2,  0,  2,  5,  4, 11, 10,  7, 11,  3,  7,  7,  0,  3, 10,  7,  8,  8,  7, 10,  3,  5, 10,  9,  0, 13, 13, 11,  5,  2,  6,  8,  8,  8, 10, 11, 11, 14,  8, 13,  6],\n",
            "        [ 1,  3,  2, 11, 14, 14,  9,  6, 10,  6,  4, 10, 12,  3,  0,  2,  3,  7, 10,  9,  9,  8,  0,  1, 14, 10, 12, 11, 11,  5,  5,  6,  2,  9,  5,  3,  7,  2,  9,  6,  6,  6,  9, 10,  3,  2,  2,  2,  2,  5,  9,  5,  6,  7,  8,  1,  1,  5,  5,  6,  6, 13,  7,  7,  6,  9,  9, 10,  5,  6,  3,  9,  8,  4,  4,  6,  5,  5,  4,  8, 12, 13, 12,  5, 14,  0,  2,  5,  6,  6,  6,  7, 11, 10,  9,  5,  5, 10,  4,  0],\n",
            "        [ 7,  7,  9,  6,  7, 12,  5,  6, 13,  9,  3,  6, 10, 11, 11, 10, 12, 14, 12,  5,  6,  7,  8, 14, 13, 12, 13, 13, 13, 12, 11, 10,  3, 10,  3,  3,  1,  5, 12,  8,  7,  2,  6, 11, 12, 12, 12, 11,  0,  8,  2,  2,  2,  1, 10, 11,  5,  9,  8,  8, 12,  6,  6,  7,  0,  3,  4,  3,  4,  8,  1,  8,  9,  5,  6, 11,  7,  7,  2,  8,  3,  6,  3,  9, 10,  1,  9, 10,  4,  5,  4,  4,  4,  4,  7, 11, 11, 12, 10,  3]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  5,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 0,  1,  4,  4,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  5,  5,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 7,  7, 10, 10,  9,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 180\n",
            "elbo: -0.8212441205978394, kl: 0.2574862539768219, recon: 0.8212698698043823\n",
            "mean: 18.8155460357666, count: 0.9196093678474426, log scale: tensor([-2.4498], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 1,  1,  8, 10,  6,  1,  2,  5,  5,  2,  6, 10, 10, 10, 10, 10,  9,  2,  2,  3, 14,  6, 13,  2,  3, 10,  4,  4, 11,  8,  8,  0,  1,  8,  5,  4,  4,  6,  7, 12,  8,  3,  6, 13, 10,  5, 10, 14,  9,  7,  8, 14, 13, 10,  9,  2,  9,  7, 10,  3,  5, 13, 14,  8,  8,  4, 10, 10, 11, 12,  9,  8, 11,  5,  8,  9,  5,  5,  9, 13, 13, 12,  9, 10, 11,  7,  8,  0,  4, 11, 11, 12,  8,  8,  8,  8,  7,  7,  6,  5],\n",
            "        [ 1,  0,  0,  4,  4,  0,  5,  8,  8,  8, 12, 11,  4,  2,  9, 13, 10, 14, 11, 12, 12, 13, 13, 13, 10,  3,  4,  4,  4,  0,  7,  8,  1,  2,  8,  8, 10, 10, 11, 11,  8,  7, 11, 14, 13, 13, 14,  0,  3, 10,  3,  2,  5, 12, 13, 13, 14, 10, 13, 11, 14,  7, 13,  4,  7,  6,  6, 11, 10, 10, 12, 12, 12, 13, 14, 11,  4, 11,  2,  7,  3,  9, 12,  8,  8,  9,  7, 14, 13, 10,  7,  5, 10, 10,  7,  5,  4,  4,  8, 14],\n",
            "        [ 0,  0,  2,  3,  7,  7,  3,  3,  7, 14, 14, 14, 13, 14, 13,  9, 11, 10,  4,  0,  8,  7,  7, 14, 13,  0,  6,  9, 13, 12,  2,  1,  8,  0,  3, 10, 11,  8,  4, 11, 11, 12,  5, 12,  8,  7,  4,  8,  8,  8, 11, 10, 11, 10, 14, 10,  3, 13,  5,  4,  1,  5,  8,  5,  6,  7,  7, 12,  9,  0,  6,  6,  4,  4,  1,  7,  6, 14, 14, 11,  7, 14,  7,  0, 14,  7,  6,  5,  5,  6,  6,  8,  7,  6,  8,  4, 11, 10, 11,  5]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[1, 1, 1, 4, 5, 7, 7, 7, 7, 7, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 7, 7, 7, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 7, 7, 7, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5],\n",
            "        [1, 1, 1, 4, 5, 7, 7, 7, 7, 7, 1, 4, 5, 5, 5, 4, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5],\n",
            "        [0, 0, 0, 5, 5, 1, 4, 5, 5, 5, 1, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 200\n",
            "elbo: -0.8271026611328125, kl: 0.34874022006988525, recon: 0.8271375298500061\n",
            "mean: 21.325702667236328, count: 0.9252343773841858, log scale: tensor([-2.4368], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 4,  3,  3,  7,  6,  6,  3,  1,  2,  4,  5,  6,  8,  4,  4, 11,  6,  7,  7,  9,  3,  3, 12, 10, 10,  8,  1,  7, 10, 14, 14,  7,  5,  9, 12, 13, 14,  6,  9,  8,  9,  4,  4,  4,  6,  5,  4,  4,  0,  0,  7, 13, 13, 14, 10,  1,  4,  5,  4,  0,  7,  6,  2,  3,  4,  4, 12,  9,  9, 14, 13, 13,  6, 10, 13, 13, 13, 13, 11, 14,  5,  5,  5,  4, 11,  8, 13, 13, 10, 10,  3,  9,  3,  7,  0,  7,  0,  4,  4,  4],\n",
            "        [ 3,  4,  4,  5,  0,  3, 11,  4,  5,  2,  2,  9,  9,  6,  6, 13, 12, 12,  8, 12,  5, 12,  9, 13, 13, 13,  9,  7, 14,  9,  5,  7,  8, 13, 14,  0, 14, 11, 14, 14,  0,  3,  1,  2,  2,  5,  6,  9,  2, 10, 14, 10,  9,  7,  8,  2,  0,  7,  0,  1,  2,  5,  4,  5,  4,  4,  0,  2,  8,  1,  4, 14, 13, 12, 13, 14, 11, 13, 12,  8, 14, 13,  9,  4,  7, 11, 10, 11, 12, 13, 13,  5,  8,  4,  6,  8,  2,  9,  8,  3],\n",
            "        [ 2,  5,  3,  3,  7, 13,  6,  5,  5,  0,  7,  7,  7,  5,  1,  0,  3,  0,  3,  4,  5,  5,  3,  3,  4, 14, 10, 10,  3,  4,  5,  5, 11,  7,  7,  8,  9,  5,  4,  3,  6,  5,  9, 13, 13,  6,  5,  3,  6,  4, 12, 10, 13, 13,  0,  0,  1,  1,  9,  6,  6, 12,  5,  5,  3,  2,  8,  8, 11,  9,  9,  5, 12,  8,  8,  4,  3, 10, 10, 14,  8, 10, 11, 12, 11, 10, 11,  7,  6,  7,  1,  1, 10, 11, 11, 10,  9, 10, 13,  4]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[1, 1, 4, 5, 5, 6, 5, 5, 5, 5, 7, 6, 6, 6, 5, 7, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
            "        [1, 1, 4, 5, 5, 6, 6, 6, 5, 5, 7, 6, 6, 6, 6, 7, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
            "        [1, 4, 4, 5, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6, 5, 7, 6, 6, 6, 6, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 220\n",
            "elbo: -0.8324770927429199, kl: 0.447602242231369, recon: 0.8325218558311462\n",
            "mean: 17.927968978881836, count: 0.9212499856948853, log scale: tensor([-2.4246], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 4,  4,  4, 11,  5,  4,  8,  9,  1,  0,  5,  3,  1,  8, 12, 12,  1,  2,  0,  0,  6,  2, 10, 11,  1, 14, 14, 10,  3,  5,  6,  7,  4,  0,  0,  1,  4,  3,  4,  3,  2,  1,  1, 12,  2,  0,  4,  1,  0,  0,  7,  1,  2,  5,  8,  8, 11,  8, 12,  2,  2,  9,  8,  8,  2,  2, 13, 13, 14, 14, 10, 10, 10, 10, 11, 10, 11, 12, 11,  4,  3, 13, 14,  7,  6,  6,  0,  6,  2,  2,  8, 11,  8,  5, 12, 14, 12,  5, 10, 11],\n",
            "        [ 7,  7,  7,  5,  7,  8,  1,  2,  1,  4,  5, 12,  4,  4,  5,  4,  9, 10,  0,  4,  4,  5,  4,  3, 13, 10, 11, 12,  0,  8,  6,  6, 13, 11, 10,  9,  4, 11,  7, 14, 14,  8,  4,  3,  4,  5, 12,  8,  9,  5,  6,  5, 13, 13,  4,  3,  8,  0,  8,  5,  8, 14,  9,  6, 10, 13, 13,  9, 11, 12, 12, 12, 13,  9, 10, 10, 13, 13, 14, 11, 11, 10,  6,  7,  1,  1,  5,  4,  2,  8,  5,  5,  6,  7,  9,  1,  4,  5,  1,  1],\n",
            "        [ 2,  7, 13,  0,  4,  4,  5, 13, 14, 13, 14, 14, 11, 11,  4,  4,  5,  5,  4,  4,  3,  4, 10, 14,  0,  2,  2,  1,  2,  5,  9,  6,  8,  9,  5,  6,  6,  4,  1, 10,  3,  4,  4, 11, 12,  8,  9, 12, 13, 12, 12,  3,  2,  0,  4, 11,  9,  1,  5,  6,  9,  9,  3,  2,  3,  3,  4,  8,  9,  8,  1,  4,  5, 12, 11,  5, 12,  4,  3,  8,  8,  8, 12,  6,  1,  0, 14, 11,  4,  2,  3,  2,  9, 13,  7,  0,  1,  4,  3,  3]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[ 4,  4,  4,  4,  5,  4,  5,  5,  5,  7,  5,  5,  5,  7,  7,  5,  5,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 7,  7,  7,  7,  8,  7,  7,  7,  8,  8,  7,  7,  7,  8,  8, 10, 10, 10,  8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  5,  5,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 4,  5,  5,  5,  7,  4,  5,  5,  5,  7,  5,  5,  5,  7,  7,  5,  5,  9,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  5,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 240\n",
            "elbo: -0.8364756107330322, kl: 0.5345193147659302, recon: 0.8365290760993958\n",
            "mean: 24.34976577758789, count: 0.9205468893051147, log scale: tensor([-2.4131], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 4, 14,  8,  9, 10, 14,  9,  2,  2,  2,  1, 12,  8,  5,  8, 11, 10,  7,  8,  1,  4,  4,  5, 12, 12, 13, 14, 11, 14,  0,  5,  4, 11,  7,  1,  2,  3,  3,  6,  3,  2,  3,  3,  1,  1,  2,  4,  0,  3,  3, 10,  4,  4,  8,  4,  9,  4,  1,  0,  3,  0,  1,  2,  2,  4,  5,  9,  3,  0,  0, 10,  3,  2, 12,  6,  2,  6,  5,  4,  4,  1,  4,  2,  0,  1,  5,  9, 13,  3,  4,  6,  1,  4,  0,  8,  8,  9, 10, 12, 13],\n",
            "        [ 4,  9, 11,  4,  0,  1,  4,  4,  5,  6,  5,  1,  0,  3,  4, 10, 14, 14, 12, 11,  7, 11, 12, 13, 14,  0,  5,  4, 12,  5,  5,  6,  2,  2,  9,  0, 14, 11, 14, 14, 13, 12,  7, 13, 11,  4,  4,  2,  4, 11,  4,  5,  2,  2,  9, 12,  9,  2,  6,  2,  6,  9,  2,  2,  1,  1,  0,  4, 11, 13, 12, 13, 11, 11,  6, 10,  3, 13, 12,  8, 13,  0, 11, 11, 11, 10, 13, 12,  0,  6,  7,  5,  9,  2,  9,  8,  8,  4,  3,  2],\n",
            "        [ 4,  3,  9, 12,  7,  4,  8,  1, 11, 12, 12, 12,  8, 11, 12,  5,  5, 12, 12, 13,  6,  0,  1,  1,  9,  6, 10, 11, 11,  6, 10,  9,  9, 13,  1,  4,  5,  7, 13, 10, 13, 10, 10, 10, 12, 14,  0, 13,  7, 12,  4,  3,  8,  8,  7,  3,  3,  4,  2,  8,  7,  8,  4,  2,  3,  2,  3,  3,  2,  0,  3,  4,  6, 10, 11, 14, 13, 13, 13,  6,  3,  9,  9,  3,  4,  9,  9,  7,  7,  7,  7,  4,  3,  5,  6,  5,  0,  3,  7,  7]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[ 4,  4,  4,  4,  4,  4,  5,  5,  7,  7,  7, 11, 11, 11, 11, 11, 11, 11,  7,  7,  7,  7,  7,  7, 11,  7,  7, 11, 11, 11,  7,  7, 11, 11, 11,  7,  7, 11, 11, 11,  4,  5,  7,  7,  7,  5,  7, 11, 11, 11, 11,  7, 11, 11, 11, 11, 11, 11, 11, 11,  4,  5,  7,  7, 11,  5,  7, 11, 11, 11,  5,  7, 11, 11, 11,  5, 11, 11, 11, 11,  4,  5,  7,  7,  7,  7,  7,  7, 11, 11,  7,  7, 11, 11, 11,  7,  7, 11, 11, 11],\n",
            "        [ 4,  4,  4,  4,  4,  4,  4,  5,  5,  7,  8,  6,  5,  5,  7,  8,  6,  5,  5,  7,  4,  7,  7,  7, 11,  7,  7, 11, 11, 11,  7,  7, 11, 11, 11,  7,  7,  7, 11, 11,  4,  5,  7,  7, 11,  7,  7, 11, 11, 11,  7,  7, 11, 11, 11, 11,  7, 11, 11, 11,  5,  7,  7,  7, 11,  5,  7, 11, 11, 11,  5,  7, 11, 11, 11,  5, 11, 11, 11, 11,  4,  5,  7,  7,  7,  7,  7,  7, 11, 11,  7,  7, 11, 11, 11,  7,  7, 11, 11, 11],\n",
            "        [ 4,  4,  4,  4,  4,  4,  4,  5,  5,  7,  7, 11, 11,  7,  7,  7, 11, 11,  7,  7,  7,  7,  7, 11, 11,  7,  7,  7, 11, 11,  7,  7,  7, 11, 11,  7,  7,  7, 11, 11,  7,  7,  7, 11, 11,  5,  7,  7, 11, 11,  5,  7, 11, 11, 11,  5,  7, 11, 11, 11,  5,  7,  7,  7, 11,  5,  7, 11, 11, 11,  5,  7, 11, 11, 11,  5, 11, 11, 11, 11,  4,  5,  7,  7,  7,  7,  7,  7, 11, 11,  7,  7, 11, 11, 11,  7,  7, 11, 11, 11]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 260\n",
            "elbo: -0.8398577570915222, kl: 0.5932978987693787, recon: 0.8399170637130737\n",
            "mean: 18.377031326293945, count: 0.923046886920929, log scale: tensor([-2.4023], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 7, 14,  4,  6,  6,  8, 11,  4, 11,  4,  4, 14,  3,  6,  6,  6, 10, 14,  1,  1,  5,  4,  2,  1,  2,  3,  7,  5,  4,  5,  9, 12,  5,  0,  7, 11, 14, 13,  8,  9,  6,  5,  2,  6, 10,  3, 10,  3,  0,  1,  2,  9,  7,  0,  7,  0,  1,  1,  9, 11,  6,  7, 10,  5,  1, 14, 14,  8,  7,  7,  8,  4,  3,  9,  9,  8,  1,  1,  3,  3,  6,  7,  3,  4,  7,  5,  6,  6, 11,  9, 13, 13, 14, 13, 13,  7, 12,  9, 11, 14],\n",
            "        [ 9,  2,  6,  0,  4,  3,  0,  0,  7,  6, 11, 12, 11, 10, 14, 10, 10, 10,  1,  1,  1, 11, 13,  6,  6, 14, 12,  0,  6,  5,  7, 11, 10, 11,  4,  3,  2,  9,  2,  3, 10, 11,  3, 11, 10, 14, 11,  8, 11,  2,  5,  9, 11, 13, 12, 12,  6, 13,  2,  6,  7,  4,  3,  5,  1,  4,  4,  9, 13,  8,  5,  5,  4,  2,  9, 11,  5,  1,  1,  0, 11, 11, 10, 14,  9,  6,  6,  8,  8,  4,  7, 14, 14,  9,  8,  8, 12,  9, 12, 13],\n",
            "        [14, 14,  4,  5,  3,  3,  4,  5,  9,  5,  9,  5, 12,  7,  6, 10,  6,  8, 12, 12, 14,  7,  8,  9,  9,  9, 11,  3,  5,  6, 12, 13,  0, 14,  6, 10,  5,  5,  1,  5,  8, 13, 11, 10,  7,  0, 14, 14, 13,  9, 10,  9, 13, 13,  9,  9,  8, 11,  0,  3,  8,  9,  4,  6,  5,  7,  1, 13, 12,  7,  5,  4, 10, 14, 14, 11,  7, 13, 12, 11,  8,  8,  8,  7,  0,  3, 10,  6,  4,  3,  0,  0,  5,  5, 12, 13,  9, 10, 10, 11]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[7, 7, 8, 8, 8, 5, 5, 5, 7, 7, 7, 4, 4, 7, 7, 7, 7, 7, 7, 7, 4, 4, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 4, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7],\n",
            "        [5, 5, 5, 7, 7, 4, 4, 4, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 4, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7],\n",
            "        [5, 5, 5, 7, 7, 4, 4, 4, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 4, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 7, 7, 7]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 280\n",
            "elbo: -0.8432028889656067, kl: 0.6414572596549988, recon: 0.843267023563385\n",
            "mean: 20.651874542236328, count: 0.9178125262260437, log scale: tensor([-2.3922], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 4,  3,  4,  8,  7, 12,  5,  1,  0,  0,  1,  4,  7,  8,  1,  0,  9,  5,  2,  6,  8, 12,  9, 10,  9,  8,  6, 12, 14,  7,  8,  7,  6,  6,  5, 10,  8,  7, 14, 12, 11, 13,  6,  6,  2,  2,  4,  3,  0, 11, 12,  4,  4,  4, 14, 13, 13, 14, 11,  6,  0, 14, 14, 14, 10, 11,  8,  7,  7,  2,  2,  1,  3,  9,  8, 13, 13, 11,  4,  7,  6,  9, 13,  0,  1,  8,  7,  5, 13, 13,  9, 10, 13,  9, 11,  0,  8,  5,  4,  9],\n",
            "        [ 1,  2,  6,  7,  8, 12, 13, 10,  5, 12,  7,  8,  4,  3,  3, 12,  6,  8,  4,  4,  8,  8,  9,  8,  4,  3,  4,  8,  8,  7, 10, 12,  6,  6,  2,  3,  4,  6,  7,  8, 11, 10,  6,  2,  8,  5,  6,  9,  5,  9,  2,  3,  2,  5, 12, 11,  9,  6,  9,  8, 13,  6,  7,  0, 13, 11, 12, 10,  0,  4,  4,  5,  8,  7,  8,  7,  7,  4, 14,  4, 14,  0, 10,  6,  8, 12, 10,  8,  2, 10,  8, 12,  2,  1, 13, 13, 10, 11, 13,  9],\n",
            "        [ 3,  4,  6,  2,  0, 13, 13, 13, 14, 13, 14, 14, 10, 14, 13,  1,  7,  6, 10, 11,  7,  2,  9, 14,  4,  8, 13, 13, 14,  8,  5,  5, 11, 14, 10, 10,  9,  2,  5, 11, 12,  3, 10,  2, 12,  5, 10,  6,  8,  3,  2,  2,  3,  3,  7,  7, 13, 14, 14, 13,  6, 13, 13, 14,  9, 13,  6, 10,  7, 11, 14,  7, 13, 12,  4,  8,  8,  8,  9,  7,  0,  1,  0,  1,  4,  5, 12, 13, 10,  9,  2,  2,  7, 12, 12, 11, 12,  9, 12, 12]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[4, 4, 4, 4, 5, 4, 7, 7, 7, 9, 5, 5, 7, 7, 9, 9, 9, 9, 9, 9, 4, 5, 5, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9],\n",
            "        [1, 1, 2, 5, 5, 9, 7, 7, 9, 9, 4, 7, 7, 9, 9, 7, 7, 9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9],\n",
            "        [3, 3, 3, 3, 4, 7, 7, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 9, 9, 9]], device='cuda:0')\n",
            "\n",
            "epoch: 0, step: 300\n",
            "elbo: -0.8465525507926941, kl: 0.7228924036026001, recon: 0.8466248512268066\n",
            "mean: 17.571483612060547, count: 0.9131249785423279, log scale: tensor([-2.3827], device='cuda:0')\n",
            "teacher forcing: False\n",
            "tensor([[ 4,  4,  9,  5,  6, 13, 14, 10, 11,  0,  6,  9,  6,  6,  5,  4,  3,  6,  5,  9, 10, 11, 11, 10,  8,  8,  8,  7, 11, 10, 12,  8,  9, 11,  8,  5,  5,  5, 14, 14,  7, 11, 10,  9,  0,  5,  4,  7,  5,  4, 11,  8, 12, 14, 11,  8,  7, 11, 11, 12,  8, 12, 13, 12, 12, 11, 11,  0,  7,  5,  9, 11,  4,  4, 11, 10,  5,  6,  6, 10, 11, 11, 12, 13, 10,  6, 13,  9,  8,  7,  0,  5,  6,  6,  6,  6,  6,  4,  1,  1],\n",
            "        [ 1,  0,  6,  7,  6,  7,  7,  4,  4,  8,  7, 12,  9, 13, 14,  9,  9, 11,  1,  5,  5,  5, 11, 10,  6,  3,  4,  4,  5,  6, 13, 14,  7,  7,  8,  6, 10,  3,  7,  8,  5,  6, 10,  6,  6,  6,  6, 13, 10, 10, 14, 14,  5,  1,  2,  4,  2,  7, 14,  7,  7, 11,  0,  0,  0,  1,  0, 10, 10,  9,  6,  6,  5,  6,  6,  1,  0,  4,  4,  8,  9,  6,  6,  8,  4,  8,  8,  8,  1,  4,  5,  4,  4,  0,  1,  3,  3,  4,  4, 11],\n",
            "        [ 0,  8,  7, 10, 13, 13, 13, 13, 11, 14,  0, 10,  7,  8,  8,  9,  9, 12,  5,  6,  2,  6,  6, 12, 12, 11, 12, 12, 12, 11, 10,  8, 14,  7,  6,  7, 10,  7, 14,  8,  8,  6,  7,  6,  8,  3,  3,  3,  7,  1,  0,  3,  0,  2,  6,  2,  2,  5,  4,  3, 10,  5,  4, 11, 12,  7,  7,  6, 10, 14,  8,  7,  0, 12, 14, 14, 10, 10,  9,  9,  3,  6,  0,  5, 12,  4,  0,  2,  4,  9,  4, 11, 10,  2,  2,  3,  1,  1,  1,  1]], device='cuda:0')\n",
            "tensor([[100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119]])\n",
            "tensor([[ 4,  4,  4,  4,  5, 10, 10,  7,  7,  7,  8,  5,  7,  7,  7, 10,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 1,  0,  5,  5,  5, 10, 10,  7,  7,  7, 10,  8,  7,  7,  7, 10, 10,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 0,  0,  4,  4,  4, 10,  5,  5,  7,  7, 10,  5,  5,  7,  7, 10,  5,  5,  7,  7,  5,  7,  7,  7,  7,  5,  7,  7,  7,  7,  5,  7,  7,  7,  7,  5,  7,  7,  7,  7,  5,  7,  7,  7,  7,  5,  7,  7,  7,  7,  5,  7,  7,  7,  7,  5,  7,  7,  7,  7,  4,  4,  7,  7,  7,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:685: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsRhtVrpw3XA"
      },
      "source": [
        "def note2scale(x):\n",
        "  n2s = {'0':60,'1':62,'2':64,'3':65,'4':67,'5':69,'6':71,\n",
        "         '7':72,'8':74,'9':76,'10':77,'11':79,'12':81,'13':83,\n",
        "         '14':84}\n",
        "  return n2s.get(str(int(x)),x)\n",
        "\n",
        "def scale2note(x):\n",
        "  s2n = {'60':0,'62':1,'64':2,'65':3,'67':4,'69':5,'71':6,\n",
        "         '72':7,'74':8,'76':9,'77':10,'79':11,'81':12,'83':13,\n",
        "         '84':14}\n",
        "  return s2n.get(str(int(x)),x)\n",
        "\n",
        "def best_fit_slope_and_intercept(xs,ys):\n",
        "    m = (((np.mean(xs)*np.mean(ys)) - np.mean(xs*ys)) / ((np.mean(xs)*np.mean(xs)) - np.mean(xs*xs)))\n",
        "    b = np.mean(ys) - m*np.mean(xs) \n",
        "    return m, b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N3eVRSP_vpE"
      },
      "source": [
        "input_height=128\n",
        "preds = vae.generate(condition=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0_z3EFhGzn9",
        "outputId": "3310e755-f0e9-4764-d5af-95494de27ac4"
      },
      "source": [
        "zeros = 0\n",
        "ones = 0\n",
        "twos = 0\n",
        "for o in range(batch_size):\n",
        "  scale = []\n",
        "  for i in list(preds[o,:]):\n",
        "    scale.append(scale2note(i))\n",
        "  xs = np.array(range(seq_len))\n",
        "  m, b = best_fit_slope_and_intercept(xs,scale)\n",
        "  if m<-0.05:\n",
        "    zeros+=1\n",
        "  elif m>0.25:\n",
        "    twos+=1\n",
        "  else:\n",
        "    ones+=1\n",
        "  print(scale,m)\n",
        "print(zeros,ones,twos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7, 7, 9, 5, 5, 5, 6, 3, 3, 8, 8, 7, 8, 8, 8, 3] 0.0058823529411764705\n",
            "[7, 6, 9, 3, 8, 2, 6, 10, 6, 11, 12, 10, 9, 2, 7, 8] 0.11764705882352941\n",
            "[7, 7, 2, 14, 9, 6, 3, 6, 6, 8, 9, 3, 9, 9, 2, 9] -0.022058823529411766\n",
            "[3, 7, 5, 4, 8, 0, 3, 6, 4, 5, 5, 13, 9, 11, 14, 8] 0.5014705882352941\n",
            "[4, 8, 14, 11, 9, 4, 11, 10, 1, 1, 0, 2, 3, 10, 10, 14] -0.07058823529411765\n",
            "[2, 1, 8, 8, 6, 8, 7, 9, 2, 5, 2, 3, 3, 3, 3, 3] -0.18088235294117647\n",
            "[11, 5, 7, 6, 10, 7, 6, 2, 2, 0, 1, 0, 3, 8, 8, 2] -0.3382352941176471\n",
            "[10, 11, 11, 10, 6, 2, 3, 3, 3, 3, 8, 3, 6, 9, 9, 9] -0.1323529411764706\n",
            "[9, 5, 9, 3, 4, 10, 8, 2, 2, 2, 3, 3, 0, 1, 2, 9] -0.31470588235294117\n",
            "[0, 10, 13, 13, 9, 9, 10, 6, 2, 6, 9, 10, 11, 10, 8, 3] -0.060294117647058824\n",
            "[7, 12, 8, 6, 5, 14, 10, 9, 4, 5, 6, 3, 2, 5, 8, 3] -0.375\n",
            "[0, 6, 11, 11, 9, 2, 4, 14, 1, 2, 6, 13, 13, 9, 5, 8] 0.19411764705882353\n",
            "[2, 2, 2, 9, 9, 6, 3, 9, 5, 4, 3, 8, 12, 2, 6, 11] 0.28088235294117647\n",
            "[14, 11, 9, 12, 13, 11, 10, 6, 6, 9, 9, 2, 9, 14, 11, 12] -0.13529411764705881\n",
            "[12, 11, 10, 6, 7, 13, 1, 10, 5, 9, 3, 3, 3, 3, 10, 10] -0.3029411764705882\n",
            "[7, 7, 9, 6, 5, 5, 3, 0, 2, 3, 3, 3, 10, 8, 6, 3] -0.10294117647058823\n",
            "[2, 3, 6, 6, 4, 0, 7, 9, 2, 6, 9, 12, 2, 2, 12, 5] 0.25441176470588234\n",
            "[9, 3, 3, 4, 0, 10, 4, 2, 11, 9, 2, 4, 3, 3, 2, 2] -0.16911764705882354\n",
            "[6, 9, 2, 2, 6, 10, 10, 10, 8, 9, 4, 4, 6, 3, 10, 10] 0.10441176470588236\n",
            "[14, 14, 7, 5, 6, 2, 6, 3, 3, 3, 8, 8, 8, 9, 6, 5] -0.22794117647058823\n",
            "[0, 13, 14, 9, 2, 9, 9, 3, 3, 3, 3, 9, 8, 8, 8, 3] -0.13823529411764707\n",
            "[13, 11, 7, 11, 7, 8, 2, 9, 9, 6, 6, 10, 11, 11, 11, 9] 0.010294117647058823\n",
            "[4, 7, 6, 3, 5, 4, 11, 12, 7, 14, 10, 2, 2, 3, 10, 8] 0.10294117647058823\n",
            "[3, 4, 3, 2, 12, 0, 14, 10, 6, 3, 9, 9, 9, 8, 10, 12] 0.4676470588235294\n",
            "[14, 11, 5, 5, 9, 2, 6, 3, 3, 3, 3, 8, 6, 6, 2, 2] -0.4235294117647059\n",
            "[6, 8, 9, 6, 3, 2, 4, 2, 8, 9, 9, 11, 10, 9, 9, 3] 0.17058823529411765\n",
            "[12, 7, 14, 0, 6, 6, 7, 9, 6, 3, 3, 3, 6, 6, 5, 4] -0.3397058823529412\n",
            "[14, 10, 7, 0, 11, 8, 6, 10, 1, 5, 12, 13, 6, 2, 9, 8] -0.12058823529411765\n",
            "[6, 8, 8, 2, 1, 7, 8, 1, 1, 6, 13, 12, 13, 12, 9, 2] 0.2897058823529412\n",
            "[4, 3, 3, 2, 7, 7, 7, 0, 12, 13, 10, 10, 12, 5, 1, 3] 0.20147058823529412\n",
            "[14, 12, 11, 7, 14, 9, 7, 13, 1, 1, 2, 3, 2, 3, 3, 11] -0.6426470588235295\n",
            "[3, 13, 12, 14, 11, 14, 7, 11, 14, 14, 9, 6, 6, 9, 3, 8] -0.28823529411764703\n",
            "[14, 13, 3, 3, 6, 6, 13, 12, 9, 12, 5, 5, 4, 2, 7, 7] -0.2985294117647059\n",
            "[11, 4, 2, 3, 2, 6, 10, 8, 9, 10, 7, 8, 10, 11, 13, 5] 0.34852941176470587\n",
            "[1, 7, 9, 5, 5, 2, 6, 10, 11, 12, 12, 10, 9, 4, 0, 3] 0.03529411764705882\n",
            "[5, 2, 8, 9, 12, 2, 2, 6, 5, 3, 9, 10, 9, 10, 5, 7] 0.1676470588235294\n",
            "[2, 3, 5, 9, 11, 14, 7, 10, 9, 9, 12, 11, 10, 1, 0, 13] 0.1264705882352941\n",
            "[10, 11, 4, 14, 8, 3, 3, 4, 0, 7, 7, 3, 10, 11, 8, 10] -0.007352941176470588\n",
            "[9, 10, 6, 7, 3, 3, 10, 14, 5, 5, 5, 12, 14, 6, 10, 5] 0.07647058823529412\n",
            "[0, 4, 4, 2, 6, 6, 6, 6, 10, 9, 2, 3, 3, 4, 2, 3] -0.0\n",
            "[7, 9, 12, 8, 7, 2, 11, 13, 6, 2, 3, 3, 8, 12, 11, 10] 0.020588235294117647\n",
            "[7, 8, 9, 7, 5, 4, 8, 8, 6, 11, 11, 9, 2, 1, 2, 3] -0.29558823529411765\n",
            "[8, 10, 11, 6, 2, 9, 3, 3, 3, 3, 14, 8, 7, 9, 8, 9] 0.06323529411764706\n",
            "[8, 7, 9, 2, 3, 7, 3, 2, 11, 10, 12, 13, 6, 2, 5, 5] 0.01911764705882353\n",
            "[7, 13, 4, 7, 3, 4, 6, 10, 11, 12, 11, 9, 2, 4, 8, 8] 0.0014705882352941176\n",
            "[0, 0, 7, 6, 9, 5, 11, 14, 5, 5, 2, 13, 12, 1, 1, 7] 0.13529411764705881\n",
            "[14, 12, 12, 5, 8, 4, 0, 3, 7, 7, 14, 8, 8, 8, 9, 6] -0.14852941176470588\n",
            "[7, 10, 9, 5, 13, 2, 8, 8, 7, 3, 8, 10, 10, 8, 3, 3] -0.18235294117647058\n",
            "[1, 0, 14, 7, 7, 2, 7, 5, 2, 6, 3, 2, 0, 1, 2, 6] -0.2073529411764706\n",
            "[3, 2, 11, 5, 6, 7, 7, 8, 10, 11, 10, 6, 2, 6, 3, 10] 0.09558823529411764\n",
            "[3, 4, 11, 8, 3, 3, 3, 9, 2, 6, 3, 3, 10, 11, 10, 9] 0.27647058823529413\n",
            "[3, 0, 12, 7, 8, 2, 9, 5, 1, 0, 4, 14, 10, 10, 10, 11] 0.40588235294117647\n",
            "[3, 3, 3, 6, 1, 12, 2, 3, 6, 9, 7, 7, 6, 5, 3, 11] 0.2691176470588235\n",
            "[3, 3, 12, 8, 10, 5, 6, 12, 13, 10, 9, 0, 4, 3, 3, 3] -0.2529411764705882\n",
            "[1, 14, 2, 10, 11, 6, 9, 3, 3, 2, 11, 14, 4, 14, 6, 8] 0.15294117647058825\n",
            "[7, 6, 9, 6, 13, 10, 7, 11, 10, 10, 13, 13, 13, 13, 0, 1] -0.05588235294117647\n",
            "[8, 11, 11, 10, 2, 0, 3, 4, 2, 10, 10, 10, 3, 5, 2, 6] -0.22205882352941175\n",
            "[14, 12, 14, 8, 5, 3, 8, 3, 3, 3, 6, 2, 4, 3, 3, 3] -0.6764705882352942\n",
            "[0, 1, 11, 4, 6, 7, 11, 13, 12, 6, 1, 4, 4, 8, 7, 8] 0.15441176470588236\n",
            "[4, 4, 10, 4, 7, 3, 7, 7, 8, 3, 9, 9, 10, 6, 5, 2] 0.03823529411764706\n",
            "[14, 11, 3, 2, 0, 1, 6, 0, 0, 0, 1, 1, 2, 3, 3, 3] -0.4117647058823529\n",
            "[9, 3, 11, 12, 5, 13, 11, 14, 8, 10, 3, 3, 3, 10, 10, 10] -0.08676470588235294\n",
            "[6, 14, 0, 4, 7, 2, 2, 2, 3, 3, 6, 6, 6, 6, 2, 0] -0.21323529411764705\n",
            "[9, 9, 12, 9, 2, 5, 8, 7, 8, 3, 3, 3, 3, 3, 8, 8] -0.2911764705882353\n",
            "[2, 13, 14, 4, 7, 5, 5, 2, 6, 2, 2, 2, 6, 9, 10, 11] 0.0058823529411764705\n",
            "[3, 9, 9, 11, 8, 1, 6, 7, 2, 3, 12, 5, 14, 13, 11, 10] 0.3264705882352941\n",
            "[14, 4, 12, 8, 8, 9, 11, 8, 4, 8, 1, 2, 6, 10, 14, 7] -0.16176470588235295\n",
            "[4, 0, 1, 0, 2, 5, 8, 4, 3, 6, 9, 10, 10, 10, 9, 2] 0.5073529411764706\n",
            "[11, 13, 14, 14, 2, 6, 9, 12, 10, 3, 2, 2, 9, 6, 11, 11] -0.2926470588235294\n",
            "[7, 11, 13, 8, 8, 5, 8, 10, 10, 13, 13, 9, 5, 8, 13, 13] 0.1411764705882353\n",
            "[10, 14, 0, 9, 2, 2, 3, 5, 5, 4, 0, 0, 2, 1, 5, 9] -0.3014705882352941\n",
            "[5, 5, 2, 3, 6, 10, 10, 8, 8, 9, 1, 1, 0, 2, 5, 2] -0.22794117647058823\n",
            "[6, 6, 13, 7, 12, 10, 2, 1, 0, 0, 2, 11, 14, 7, 8, 3] -0.11176470588235295\n",
            "[5, 4, 1, 5, 3, 8, 8, 5, 4, 5, 4, 3, 4, 4, 3, 7] 0.016176470588235296\n",
            "[8, 7, 5, 4, 5, 3, 3, 12, 9, 9, 12, 9, 2, 6, 10, 8] 0.17647058823529413\n",
            "[2, 9, 10, 10, 9, 7, 7, 12, 0, 1, 2, 3, 10, 11, 12, 12] 0.1514705882352941\n",
            "[13, 13, 8, 2, 8, 11, 11, 11, 6, 9, 2, 3, 3, 9, 9, 6] -0.3352941176470588\n",
            "[0, 7, 6, 6, 6, 2, 12, 14, 2, 2, 2, 0, 12, 10, 10, 10] 0.2985294117647059\n",
            "[8, 5, 7, 7, 6, 13, 9, 8, 4, 5, 5, 5, 0, 13, 5, 6] -0.1323529411764706\n",
            "[0, 4, 13, 11, 7, 7, 8, 13, 5, 3, 2, 1, 2, 0, 6, 11] -0.18088235294117647\n",
            "[8, 8, 12, 12, 2, 2, 6, 3, 3, 3, 3, 8, 3, 3, 6, 9] -0.225\n",
            "[2, 5, 2, 8, 7, 2, 5, 2, 3, 3, 8, 6, 6, 2, 1, 2] -0.07647058823529412\n",
            "[2, 12, 11, 3, 3, 6, 10, 11, 4, 2, 5, 6, 10, 2, 6, 8] -0.057352941176470586\n",
            "[14, 3, 9, 5, 5, 2, 7, 3, 3, 7, 3, 3, 8, 8, 8, 6] -0.07058823529411765\n",
            "[10, 14, 10, 8, 3, 12, 12, 11, 6, 11, 3, 2, 3, 3, 10, 10] -0.34411764705882353\n",
            "[6, 9, 6, 3, 3, 5, 11, 10, 6, 6, 9, 6, 6, 8, 7, 8] 0.11029411764705882\n",
            "[8, 5, 5, 9, 7, 7, 14, 11, 9, 9, 9, 10, 10, 10, 8, 6] 0.12794117647058822\n",
            "[14, 11, 10, 10, 9, 5, 5, 5, 2, 2, 3, 3, 8, 8, 6, 9] -0.3588235294117647\n",
            "[11, 7, 2, 9, 6, 4, 14, 10, 4, 3, 1, 5, 13, 13, 14, 3] 0.09852941176470588\n",
            "[2, 3, 7, 8, 4, 3, 3, 6, 0, 6, 6, 9, 9, 6, 10, 2] 0.2088235294117647\n",
            "[13, 12, 14, 7, 12, 12, 14, 8, 5, 8, 9, 13, 13, 0, 1, 13] -0.4\n",
            "[5, 10, 10, 12, 5, 6, 6, 0, 0, 4, 8, 9, 10, 10, 12, 11] 0.19117647058823528\n",
            "[0, 8, 9, 2, 2, 8, 8, 4, 3, 2, 6, 3, 7, 12, 11, 9] 0.3382352941176471\n",
            "[7, 14, 13, 2, 1, 5, 12, 9, 3, 7, 0, 1, 8, 6, 10, 11] -0.08970588235294118\n",
            "[7, 8, 8, 10, 5, 9, 2, 11, 8, 9, 6, 9, 1, 1, 5, 9] -0.2\n",
            "[8, 7, 13, 2, 7, 2, 10, 0, 1, 7, 12, 12, 5, 6, 7, 7] 0.01764705882352941\n",
            "[4, 10, 5, 9, 0, 7, 7, 3, 3, 3, 2, 2, 3, 3, 6, 3] -0.24411764705882352\n",
            "[4, 7, 2, 10, 8, 9, 7, 2, 2, 3, 6, 11, 12, 12, 8, 6] 0.2426470588235294\n",
            "[3, 7, 12, 11, 4, 4, 8, 5, 11, 12, 13, 12, 5, 1, 4, 5] -0.09558823529411764\n",
            "[7, 3, 6, 0, 1, 5, 6, 2, 2, 6, 7, 11, 12, 5, 4, 3] 0.19117647058823528\n",
            "50 37 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtBQuZkj5lrS"
      },
      "source": [
        "## Convert to MIDI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6DdZkrJAfus"
      },
      "source": [
        "new_pred = preds[:10]\n",
        "new_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PBQzdd5AjiI"
      },
      "source": [
        "count = 1\n",
        "composer='88_16_'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIMGdm715kq3"
      },
      "source": [
        "for repr in new_pred:\n",
        "  print(repr.shape)\n",
        "  velocity = 0\n",
        "  t = 0\n",
        "  track = mido.MidiTrack()\n",
        "  for r in repr:\n",
        "    # rr = int(np.argmax(r))\n",
        "\n",
        "    rr = int(r)\n",
        "      \n",
        "    if rr < 88:\n",
        "      note = rr#+21\n",
        "      print(note)\n",
        "      t = int(mido.second2tick(0.25, 384, 500000))\n",
        "      track.append(mido.Message('note_on', note=note, time=0, velocity=80))\n",
        "      track.append(mido.Message('note_off', note=note, time=t, velocity=80))\n",
        "      t = 0\n",
        "    else: print('wtf!')\n",
        "\n",
        "  mid_f = mido.MidiFile(type=1, ticks_per_beat=384)\n",
        "\n",
        "  meta_track = mido.MidiTrack()\n",
        "  meta_track.append(mido.MetaMessage('set_tempo', tempo=500000, time=0))\n",
        "  meta_track.append(mido.MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0))\n",
        "  meta_track.append(mido.MetaMessage('end_of_track', time=1))\n",
        "\n",
        "  mid_f.tracks.append(meta_track)\n",
        "  mid_f.tracks.append(track)\n",
        "\n",
        "  mid_f.save('/content/drive/MyDrive/Colab Notebooks/piano_generation/gen/'+composer+ str(count) +'.midi')\n",
        "  count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h4LQGjW5MZi"
      },
      "source": [
        "# Other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IsK12gcgkNZ"
      },
      "source": [
        "# TEST\n",
        "test_tensor = data[120].unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    z, _ = vae.encoder(test_tensor)\n",
        "    _, quantized, _, _ = vae.vq_vae(z)\n",
        "    pred, _ = vae.decoder(quantized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNr9I-DnhTbh",
        "outputId": "7cfde759-6466-4bf8-8593-9b7b99a09be1"
      },
      "source": [
        "print(np.argmax(test_tensor,axis=2))\n",
        "print(torch.argmax(pred,axis=-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 46,  88,  62,  89,  56,  88,  32,  90,  44, 103,  63,  88,  39,  89,  55,  88,  58,  89,  38,  88,  26,  90,  27, 102,  58,  91,  62,  91,  50,  99,  43,  91,  63,  90,  55,  88,  51, 100,  64,  89,  52,  89,  60,  89,  44,  88,  48, 102,  65,  88,  56,  89,  53, 102,  61,  88,  49,  89,  56,  89,  41,  90,  44, 101,  62,  88,  56,  88,  53,  89,  50, 100,  46,  89,  53,  88,  63,  89,  44,  88,  56,  88,  55,  89,  32,  88,  62,  89,  34,  88,  58, 102,  39,  88,  55,  89,  58,  88,  63,  88]])\n",
            "tensor([ 46,  88,  62,  89,  56,  88,  32,  90,  44, 103,  63,  88,  39,  89,  55,  88,  58,  89,  38,  88,  26,  90,  27, 102,  58,  91,  62,  91,  50,  99,  43,  91,  63,  90,  55,  88,  51, 100,  64,  89,  52,  89,  60,  89,  44,  88,  48, 102,  65,  88,  56,  89,  53, 102,  61,  88,  49,  89,  56,  89,  41,  90,  44, 101,  62,  88,  56,  88,  53,  89,  50, 100,  46,  89,  53,  88,  63,  89,  44,  88,  56,  88,  55,  89,  32,  88,  62,  89,  34,  88,  58, 102,  39,  88,  55,  89,  58,  88,  63,  88])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2k57vCSPchq"
      },
      "source": [
        "z = (torch.rand(z.shape)-0.5)*1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT_2TAUZh5-0",
        "outputId": "aa2d4a9d-fe24-49b1-b569-c9d5f4cbd08f"
      },
      "source": [
        "print(torch.min(z), torch.max(z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.7499) tensor(0.7499)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpz3dQi4PwiN"
      },
      "source": [
        "# SAMPLE\n",
        "with torch.no_grad():\n",
        "    _, quantized, _, _ = vae.vq_vae(z)\n",
        "    pred, _ = vae.decoder(quantized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE9U4J79P0Y_",
        "outputId": "e1f89bd3-7750-4b31-fe2f-362f7883553f"
      },
      "source": [
        "print(torch.argmax(pred,axis=-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 25,  88, 100,  90, 100,  58, 100,  96, 100, 101, 100, 112,  37, 101, 100, 112, 100, 101, 100, 101, 100,  96, 100, 112, 100, 101,  47, 104, 100, 101, 100, 101, 100,  58,  47, 101, 100, 101, 100, 101, 100,  90, 100, 101, 100, 101, 100, 104, 100, 101, 100,  96, 100, 112, 100, 112, 100, 212, 100,  98, 100,  51, 100, 104, 100, 101, 100,  88, 100,  90,  47, 101, 100, 104, 100, 101,  47, 101, 100,  90, 100,  90,  62, 101, 100, 118, 100, 101, 100,  90,  47, 101, 100,  90, 100, 101, 100, 101, 100, 101])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rypmf2Xxjt9Y"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-6jPgGdjze1"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx5YwYzd93OV"
      },
      "source": [
        "vae = VAE().load_from_checkpoint('/content/drive/MyDrive/Colab Notebooks/piano_generation/models/lightning_logs/version_312/checkpoints/epoch=24-step=16999.ckpt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFKwFzNljqkZ"
      },
      "source": [
        "data = Maestro('/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/mido_100_short_combined.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWt82gOjYRzz"
      },
      "source": [
        "for param_tensor in vae.state_dict():\n",
        "    print(param_tensor, \"\\t\", vae.state_dict()[param_tensor])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6QURxazkUcS"
      },
      "source": [
        "## Verify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28zAts2-0iiP"
      },
      "source": [
        "# test_tensor = data[-1].unsqueeze(0)\n",
        "# test_tensor = data[0][0]\n",
        "# test_tensor = torch.swapaxes(test_tensor,0,1)\n",
        "# # test_tensor = test_tensor.mean(axis=1)\n",
        "# print(test_tensor.shape)\n",
        "# # test_tensor2 = torch.zeros_like(test_tensor[:,0,:,:])\n",
        "# print(test_tensor2.shape)                                \n",
        "# for i in range(101):\n",
        "#   test_tensor2[:,i,:] = test_tensor[:,i,i,:]\n",
        "# print(data[0][0])\n",
        "test_tensor = data[120][0].unsqueeze(0)#[:,:,:-10]\n",
        "# cond = data[0][1].unsqueeze(0)\n",
        "# print(test_tensor.shape, cond.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr2w59LK2RlM",
        "outputId": "19af354d-c858-4e72-f9b9-efcd2d26c5b7"
      },
      "source": [
        "tt = np.argmax(test_tensor,axis=-1)[0]\n",
        "min(tt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96fwN_FN2mSN",
        "outputId": "a84cd645-add2-4cb9-886d-34362779660e"
      },
      "source": [
        "np.nanmin(np.where(tt<88,tt,np.nan))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVT25J_WUD4T"
      },
      "source": [
        "np.where(# test_tensor = F.one_hot(torch.tensor([1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2]),413).unsqueeze(0).type(torch.FloatTensor)\n",
        "# test_tensor.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DfEpjl-q3Al"
      },
      "source": [
        "num_preds = 1\n",
        "p = torch.distributions.Normal(torch.zeros_like(test_tensor), torch.ones_like(test_tensor)*0.01)\n",
        "z2 = p.rsample((num_preds,))\n",
        "test_tensor2 = test_tensor #+ z2.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL-_c4tAtz2W",
        "outputId": "87f8def0-2b0d-4032-bc8b-4e8af1420aa9"
      },
      "source": [
        "test_tensor2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 88])"
            ]
          },
          "metadata": {},
          "execution_count": 503
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBtRWiKa0b_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "865eefd7-94b5-4cad-e407-cd8b428209c2"
      },
      "source": [
        "# TES\n",
        "batch_size = 1\n",
        "with torch.no_grad():\n",
        "    encoder_hidden = vae.encoder.init_hidden(batch_size)\n",
        "    x_encoded, encoder_hidden = vae.encoder(test_tensor, encoder_hidden)\n",
        "    # x_encoded, encoder_hidden = vae.encoder(test_tensor)\n",
        "    # mu, log_var = vae.fc_mu(x_encoded), vae.fc_var(x_encoded)\n",
        "    # z = vae.reparameterize(mu, log_var)\n",
        "    z = x_encoded\n",
        "    # z = torch.cat((z,cond),-1)\n",
        "    decoder_hidden = vae.decoder.init_hidden(batch_size)\n",
        "    pred, decoder_hidden = vae.decoder(z,decoder_hidden)\n",
        "    # pred, _ = vae.decoder(z)\n",
        "ones = torch.argmax(pred,axis=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-194-dfe3ac831514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# x_encoded, encoder_hidden = vae.encoder(test_tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: init_hidden() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8UM9_vw4TWj",
        "outputId": "a26e8bcb-b0aa-4698-d9ed-7991fe2b0db4"
      },
      "source": [
        "print(np.argmax(test_tensor,axis=-1)[0])\n",
        "print(torch.argmax(pred,axis=-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([65, 62,  0])\n",
            "tensor([65, 62,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nazwN0B63KpH",
        "outputId": "8c4c683a-ce53-426c-b4e7-e3b773134875"
      },
      "source": [
        "\n",
        "print(torch.argmax(pred,axis=-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([28, 24, 44, 36, 24, 46, 36, 42, 24, 24, 36, 44, 42, 24, 44, 36])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK9DXkh-3lCt",
        "outputId": "b3c854c9-5434-439e-c5bb-be0d0f18d8d5"
      },
      "source": [
        "print(z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 50, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFhSrOZd3IoD",
        "outputId": "5b5a8d0f-cc03-484c-a174-39d78278003c"
      },
      "source": [
        "test_z.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 50, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6xpJ86-LdE"
      },
      "source": [
        "p = 0.9\n",
        "test_z = (((z[0]*p)+(z[-10]*(1-p)))).repeat(50,1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fPxKEBJ3UBr"
      },
      "source": [
        "with torch.no_grad():\n",
        "    decoder_hidden = vae.decoder.init_hidden(batch_size)\n",
        "    new_pred, decoder_hidden = vae.decoder(test_z, decoder_hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "MUUjYL4F1fyZ",
        "outputId": "b1633d12-fd95-479e-934f-e16c5a8df85a"
      },
      "source": [
        "plt.scatter(range(seq_len), np.argmax(pred,axis=-1)[0])\n",
        "plt.show()\n",
        "plt.scatter(range(seq_len), np.argmax(new_pred[0],axis=-1))\n",
        "plt.show()\n",
        "plt.scatter(range(seq_len), np.argmax(pred,axis=-1)[-10])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbpu0BpY2faK",
        "outputId": "b52db4c5-cee5-40c8-c7dc-45bf6ddf23c4"
      },
      "source": [
        "np.argmax(test_av)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([39, 29, 26, 41, 44, 28, 25, 43, 32, 27, 44, 24, 33, 42, 38, 22, 46, 50, 24, 21, 34, 58, 22, 19, 51,  6, 18,  8, 20, 10, 20, 11, 23, 13, 17, 56, 20, 41, 14, 32, 35, 13, 42, 59, 23, 12, 52, 60, 58, 34])"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "z9j2qFh4mpGi",
        "outputId": "fec9a570-d8f6-4406-bf96-d39755b029c1"
      },
      "source": [
        "ex = torch.zeros(100,256)\n",
        "num_preds = 200\n",
        "p = torch.distributions.Normal(torch.zeros_like(ex), torch.ones_like(ex))\n",
        "\n",
        "looping = True\n",
        "\n",
        "while looping: \n",
        "\n",
        "  time_errors = 0\n",
        "  note_errors = 0\n",
        "  total_errors = 0\n",
        "\n",
        "  z2 = p.rsample((num_preds,))\n",
        "  with torch.no_grad():\n",
        "    decoder_hidden = vae.decoder.init_hidden(num_preds)\n",
        "    pred, decoder_hidden = vae.decoder(z2, decoder_hidden)\n",
        "      # pred, _ = vae.decoder(z2)\n",
        "\n",
        "  pred = pred[10].unsqueeze(0)\n",
        "  ones = pred.argmax(axis=-1).squeeze().tolist()\n",
        "\n",
        "  for i,n in enumerate(ones):\n",
        "    if i > 0:\n",
        "      if n >= 88 and ones[i-1] >=88 and n != 212 and ones[i-1] != 212:\n",
        "        time_errors += 1\n",
        "      if n < 88 and ones[i-1] < 88: \n",
        "        note_errors += 1\n",
        "  total_errors = time_errors + note_errors\n",
        "  if total_errors <= 0:\n",
        "    looping = False\n",
        "\n",
        "  print(f'total: {total_errors}, time: {time_errors}, note: {note_errors}')     \n",
        "ones        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total: 16, time: 10, note: 6\n",
            "total: 17, time: 13, note: 4\n",
            "total: 22, time: 11, note: 11\n",
            "total: 15, time: 6, note: 9\n",
            "total: 25, time: 16, note: 9\n",
            "total: 8, time: 5, note: 3\n",
            "total: 14, time: 3, note: 11\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-3b862eadc50a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0;31m# pred, _ = vae.decoder(z2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-5e584c5c64f3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_input, hidden)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 680\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoudU7-RniJb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOMBEDX8L9uK"
      },
      "source": [
        "new_pred = pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG5fC0o6YUTr",
        "outputId": "f4c08f8f-e3bd-4ecb-ad2c-314ec7cefcc3"
      },
      "source": [
        "z[0,1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhDuDiuDNKoI",
        "outputId": "7d4c40c6-c014-433f-ccb6-21c2d6cebbdd"
      },
      "source": [
        "z[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "aBtoi1jr4fwU",
        "outputId": "1a2d05fa-d65a-4137-bd48-c1e2756967f7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(z[0],bins=50)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import math\n",
        "\n",
        "mu = 0\n",
        "sigma = 1\n",
        "# sigma = math.sqrt(variance)\n",
        "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
        "plt.plot(x, stats.norm.pdf(x, mu, sigma)*50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18iq7_zkXrV"
      },
      "source": [
        "## Generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bmvL302rUY2"
      },
      "source": [
        "# r_len=51"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "Ua93_yvsIcRt",
        "outputId": "ee74af48-c5d2-4772-fe06-7ca5c3181ca1"
      },
      "source": [
        "# torch.ones_like(ex)*np.exp(vae.log_scale[0].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-27721f6cfce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_scale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ex' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrW7Fb5lRaRQ",
        "outputId": "9679f291-72aa-410f-e10a-90d2e731a198"
      },
      "source": [
        "ex = torch.zeros(1,88)\n",
        "num_preds = 10\n",
        "batch_size = 10\n",
        "# cond = torch.zeros(2,1,88)\n",
        "# cond[:,:,1]=2\n",
        "# cond = torch.Tensor([[[0,0,1]]]).repeat(10,1,1)\n",
        "cond = torch.zeros(1,1,88)\n",
        "cond[:,:,1]=1\n",
        "cond = cond.repeat(10,1,1)\n",
        "print(cond.shape)\n",
        "p = torch.distributions.Normal(torch.zeros_like(ex), torch.ones_like(ex))\n",
        "z2 = p.rsample((num_preds,))\n",
        "print(z2.shape)\n",
        "# z2 = torch.cat((cond,z2),-1)\n",
        "decoder_input=z2\n",
        "print(decoder_input.shape)\n",
        "# SAMPLE\n",
        "decoder_outputs = torch.zeros(batch_size, seq_len, vae.decoder.hidden_size, device=vae.device)\n",
        "with torch.no_grad():\n",
        "  decoder_hidden = vae.decoder.init_hidden()\n",
        "  ### NO TEACHER FORCING\n",
        "  for s in range(seq_len+1):\n",
        "    if s == 0:\n",
        "       _, decoder_hidden = vae.decoder(cond, decoder_hidden)\n",
        "    else:\n",
        "      decoder_output, decoder_hidden = vae.decoder(decoder_input, decoder_hidden)\n",
        "      decoder_input = F.one_hot(torch.argmax(decoder_output,-1),88).type(torch.FloatTensor).to(vae.device)\n",
        "      decoder_outputs[:,s-1] = decoder_output.squeeze(1)\n",
        "    # pred, decoder_hidden = vae.decoder(z2, decoder_hidden)\n",
        "    # pred, _ = vae.decoder(z2)\n",
        "pred = decoder_outputs\n",
        "# pred = pred.unsqueeze(0)\n",
        "ones = pred.argmax(axis=2)\n",
        "scale = []\n",
        "for i in list(ones[0,:]):\n",
        "  scale.append(scale2note(i))\n",
        "xs = np.array(range(10))\n",
        "m, b = best_fit_slope_and_intercept(xs,scale)\n",
        "print(scale,m)\n",
        "# print(ones)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 1, 88])\n",
            "torch.Size([10, 1, 88])\n",
            "torch.Size([10, 1, 88])\n",
            "[0, 6, 2, 4, 7, 6, 5, 2, 2, 1]\n",
            "[0, 6, 2, 4, 7, 6, 5, 2, 2, 1] -0.10303030303030299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gVnue1wkBrV"
      },
      "source": [
        "# ex = torch.zeros(0,256)\n",
        "\n",
        "# # num_preds = 1\n",
        "# # p = torch.distributions.Normal(torch.zeros_like(ex), torch.ones_like(ex))\n",
        "# # z2 = p.rsample((num_preds,))\n",
        "# # print(z2.shape)\n",
        "# # print(z2)\n",
        "# # z_cond = torch.cat((z2,cond),-1) \n",
        "# # z3 = torch.cat((z,z_cond),1)\n",
        "# # print(z3.shape, z3)\n",
        "# # # SAMPLE\n",
        "# # with torch.no_grad():\n",
        "# #     pred, _ = vae.decoder(z3)\n",
        "\n",
        "# num_preds = 1\n",
        "# p = torch.distributions.Normal(torch.zeros_like(ex), torch.ones_like(ex)*.5)\n",
        "# z = p.rsample((num_preds,))\n",
        "# print(z.shape)\n",
        "# print(z)\n",
        "\n",
        "\n",
        "# # cond = torch.tensor(np.array([[1,0,0,0,0,0,0,0,0,0]]).repeat(50,0)).unsqueeze(0)\n",
        "# # # print(cond.shape,z2.shape)\n",
        "# # z_cond = torch.cat((z,cond),-1)\n",
        "\n",
        "\n",
        "\n",
        "# # SAMPLE\n",
        "# with torch.no_grad():\n",
        "#     _, quantized, _, _ = vae.vq_vae(z)\n",
        "#     pred, _ = vae.decoder(quantized)\n",
        "\n",
        "# pred = pred.unsqueeze(0)\n",
        "# ones = pred.argmax(axis=2)\n",
        "# ones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z3-gruaPfSY"
      },
      "source": [
        "# pred[0][:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZJrrWegTS-6"
      },
      "source": [
        "# pred2=pred+torch.distributions.Normal(0,0.1).rsample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkDw_X1YPSx5"
      },
      "source": [
        "# plt.bar(range(413),pred2[50],width=4)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0wgbnVWFyLr"
      },
      "source": [
        "# print(pred[0].max(axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NirCnQ5iQRqX"
      },
      "source": [
        "# test = np.argmax(test_tensor,axis=2)\n",
        "# print(test)\n",
        "# # ones[0]\n",
        "# ons = 0\n",
        "# offs = 0\n",
        "# vs = 0\n",
        "# ts = 0\n",
        "# for n in test.flatten():\n",
        "#   if n<127:\n",
        "#     ons+=1\n",
        "#   elif n<255:\n",
        "#     offs+=1\n",
        "#   elif n<287:\n",
        "#     vs+=1\n",
        "#   else:\n",
        "#     ts+=1\n",
        "# print(ons,offs,vs,ts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63FdQq9LJhCG"
      },
      "source": [
        "# pred = np.random.rand(10,249,413)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "wEu_rOG0uUgm",
        "outputId": "4544adca-06eb-4889-b94f-084d6a477d85"
      },
      "source": [
        "rand = np.random.randint(0,213,(1,1,101))\n",
        "new_pred = np.zeros_like(rand)\n",
        "for j in range(new_pred.shape[0]):\n",
        "  for i in range(new_pred.shape[1]):\n",
        "    new_pred[j,i,rand[j,i]]=1\n",
        "rand"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-3cd56c72a16c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnew_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 189 is out of bounds for axis 2 with size 101"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbqisk7NsPCw"
      },
      "source": [
        "ones = pred.argmax(axis=-1)\n",
        "# ones = pred.argmax(axis=-1)\n",
        "new_pred = np.zeros_like(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIBF760xwqdR",
        "outputId": "39712ba8-31b9-4995-f2fa-d530433ba6e9"
      },
      "source": [
        "ones.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 101])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le3voobiM3iq"
      },
      "source": [
        "# ones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5bzSvlE5ncr"
      },
      "source": [
        "# for i in range(new_pred.shape[0]):\n",
        "#   new_pred[i,ones[i]]=1\n",
        "# with np.printoptions(linewidth=1000):\n",
        "#     print(np.argmax(new_pred,axis=1))\n",
        "# new_pred = np.expand_dims(new_pred,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swQLrorwwAOm"
      },
      "source": [
        "for j in range(new_pred.shape[0]):\n",
        "  for i in range(new_pred.shape[1]):\n",
        "    new_pred[j,i,ones[j,i]]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wDie5VZEuLCx",
        "outputId": "188a5d2b-09e9-4d64-b4d1-b5bb309e0dbf"
      },
      "source": [
        "# with np.printoptions(linewidth=1000):\n",
        "#   for i in range(10):\n",
        "#     print(np.argmax(new_pred[i],axis=-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 46  88  62  89  88  88  32  90  41  39 114  88  39  89  55  88 107  89 100  88  37  90  32 102  45  91  58  91  42  46  90  91  29  90  92  88 102 102  60  89  38  89  60  89  41  88  89 102  56  88  56  65  90  22  89  65 129 132  58  98 134  38  63  41  30 130  64  19  41  97  68  11  28 107  22  20  88  41  44  35  74  99  53  90  66  52  99 103 113 123 136   9  93 111 113 104  95  49  18  31]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-024ca49b10e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs8M5jwzbLNk",
        "outputId": "4f236287-064e-4487-d561-b6f834155ad3"
      },
      "source": [
        "ones"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 21, 125,  19,  ...,  24, 116,  22],\n",
              "        [ 88,  46,  90,  ..., 117,  29, 119],\n",
              "        [ 37,  88,  32,  ...,  20, 122,   8],\n",
              "        ...,\n",
              "        [ 90,  58, 103,  ...,  89,  65, 101],\n",
              "        [ 20, 104,  25,  ...,  51,  91,  13],\n",
              "        [ 93,  50,  96,  ...,  89,  36,  90]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAWcb4yjRmaQ",
        "outputId": "9ec223ff-c6aa-4db8-d777-3a286e7e20a8"
      },
      "source": [
        "np.argmax(new_pred,-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]])"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JLUh1ORjUE8"
      },
      "source": [
        "## Convert to MIDI 413"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df-iwmVQaG8G"
      },
      "source": [
        "count = 3000\n",
        "composer='long'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fBiSejowRSF"
      },
      "source": [
        "for repr in ones:\n",
        "  velocity = 0\n",
        "  time = 0\n",
        "  t = 0\n",
        "  track = mido.MidiTrack()\n",
        "  for r in repr:\n",
        "    rr = int(r)\n",
        "    # rr = int(np.argmax(r))\n",
        "\n",
        "    # 413 different events\n",
        "    # ----------------------\n",
        "    # NOTE ON starts at 0\n",
        "    # NOTE OFF starts at 128\n",
        "    # TIME-SHIFT starts at 256\n",
        "    # VELOCITY STARTS AT 381 \n",
        "\n",
        "    if rr >=381:\n",
        "      velocity = (rr-381)*4\n",
        "      \n",
        "    elif rr >=256:\n",
        "      time += (rr-256)*8/1000\n",
        "      t = int(mido.second2tick(time, 384, 500000))\n",
        "    elif rr >=128:\n",
        "      note = rr-128\n",
        "      track.append(mido.Message('note_on', note=note, time=t, velocity=0))\n",
        "      time = 0\n",
        "      t = 0\n",
        "    elif rr < 128:\n",
        "      note = rr\n",
        "      # print(t)\n",
        "      # print(velocity)\n",
        "      track.append(mido.Message('note_on', note=note, time=t, velocity=velocity))\n",
        "      time = 0\n",
        "      t = 0\n",
        "    else: print('wtf!')\n",
        "\n",
        "  mid_f = mido.MidiFile(type=1, ticks_per_beat=384)\n",
        "\n",
        "  meta_track = mido.MidiTrack()\n",
        "  meta_track.append(mido.MetaMessage('set_tempo', tempo=500000, time=0))\n",
        "  meta_track.append(mido.MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0))\n",
        "  meta_track.append(mido.MetaMessage('end_of_track', time=1))\n",
        "\n",
        "  mid_f.tracks.append(meta_track)\n",
        "  mid_f.tracks.append(track)\n",
        "\n",
        "  mid_f.save('/content/drive/MyDrive/Colab Notebooks/piano_generation/gen/'+composer+ str(count) +'.midi')\n",
        "  count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEM_-ovgj7S-"
      },
      "source": [
        "## Encode MIDI 413"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "6251a4d59d9a42a49344fc48b935b7dc",
            "6a99937dcc5349e1b9349550f86886b3",
            "7a79d1afb35f467ebfadb67f49773dac",
            "f19577612f8d44bda00a09717934a408",
            "a97c48c4188d4a7ca4e6bc2300d6a318",
            "d5155f6a7e4b47a1849ca74c2997e4ee",
            "5e94cd78ee914fcc8f0f2cf647461cd9",
            "6c9081b764eb4e5990d80713ed901627",
            "41b1bbae47564049881f16f824661941",
            "8c8107828c4248bd95f7051ae100f4db",
            "f962ee5586824e10b065061edcd4f9b8",
            "713c48f878f54d3a97a5b458c6007dd2",
            "63720f367c5449c48c3be709069b11b1",
            "9272d79ad21149e79676826c566f7eea",
            "e4f4d26547544a23baa233d89419bc05",
            "2c1feeb0387a4472ad2ac3d56ede42e0"
          ]
        },
        "id": "8CaozN1hye6o",
        "outputId": "cf8aed26-0427-4ea5-a1cf-b90e7b9b2945"
      },
      "source": [
        "t_len = 100\n",
        "r_len = t_len+1\n",
        "\n",
        "# years = ['2009a','2014a','2013a','2018a','2017a','2008a','2015a','2006a','2011a','2004a','2009b','2014b','2013b','2018b','2017b','2008b','2015b','2006b','2011b','2004b']\n",
        "years = ['32']\n",
        "\n",
        "for year in tqdm(years):\n",
        "\n",
        "  representations = []\n",
        "\n",
        "  for midname in tqdm(os.listdir('/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/'+year)):\n",
        "    mid = mido.MidiFile('/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/'+year+'/'+midname)\n",
        "\n",
        "    i = 0\n",
        "    total_time = 0\n",
        "    time = 0\n",
        "    representation = []\n",
        "\n",
        "    last_v = 0\n",
        "    last_event_time = 0\n",
        "\n",
        "    for msg in mid:\n",
        "\n",
        "      # 413 different events\n",
        "      # ----------------------\n",
        "      # NOTE ON starts at 0\n",
        "      # NOTE OFF starts at 128\n",
        "      # TIME-SHIFT starts at 256\n",
        "      # VELOCITY STARTS AT 381 \n",
        "\n",
        "      #print(msg.type, msg.time,'s ',msg.time*1000,'ms')\n",
        "\n",
        "      # print(msg)\n",
        "\n",
        "\n",
        "    # get time\n",
        "      total_time+=msg.time*1000 \n",
        "      time+=msg.time*1000\n",
        "      # print(total_time, time)\n",
        "\n",
        "      # check how many seconds elapsed\n",
        "      r = time/1000\n",
        "      # if greater than 1 second \n",
        "      if r > 1: \n",
        "        event = np.zeros(413)\n",
        "        event[380]=1\n",
        "        # then add a time_shift event for each second\n",
        "        for i in range(int(r)):\n",
        "          # print('time: ', 125, 380)\n",
        "          representation.append(event)\n",
        "          if len(representation)==r_len:   \n",
        "            representations.append(representation)\n",
        "            representation=[]\n",
        "          time-=1000\n",
        "\n",
        "      if msg.type=='note_on':\n",
        "        # then we want to save a time event\n",
        "        t = int(time/8)\n",
        "        time -= (t*8)\n",
        "        event = np.zeros(413)\n",
        "        event[256+t]=1\n",
        "        # print('time: ', t, 256+t)\n",
        "        representation.append(event)\n",
        "        if len(representation)==r_len:   \n",
        "          representations.append(representation)\n",
        "          representation=[]\n",
        "\n",
        "        if msg.velocity == 0:\n",
        "    # get note off\n",
        "          # print('off: ', msg.note, 128+msg.note)\n",
        "          event = np.zeros(413)\n",
        "          event[128+msg.note]=1\n",
        "          representation.append(event)\n",
        "          if len(representation)==r_len:   \n",
        "            representations.append(representation)\n",
        "            representation=[]    \n",
        "        else:\n",
        "    # get velocity   \n",
        "          # print('velocity: ', msg.velocity)\n",
        "          v = msg.velocity//4\n",
        "          if v != last_v:\n",
        "            event = np.zeros(413)\n",
        "            event[381+v]=1\n",
        "          # print('velocity: ', v, 381+v)\n",
        "          representation.append(event)\n",
        "          if len(representation)==r_len:   \n",
        "            representations.append(representation)\n",
        "            representation=[]\n",
        "          # print('velocity_bin: ', v)\n",
        "    # get note on\n",
        "          # print('on: ', msg.note, msg.note)\n",
        "          event = np.zeros(413)\n",
        "          event[msg.note]=1\n",
        "          representation.append(event) \n",
        "          if len(representation)==r_len:   \n",
        "            representations.append(representation)\n",
        "            representation=[]\n",
        "\n",
        "  rmax = np.argmax(np.array(representations),axis=2).astype(int)\n",
        "  np.savetxt('/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/mido_100_'+year+'.csv', rmax, fmt='%s', delimiter=',')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6251a4d59d9a42a49344fc48b935b7dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41b1bbae47564049881f16f824661941",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwa0XWgW0--Q"
      },
      "source": [
        "## Encode MIDI 213"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "446e93394a044c1dbd32f6f96931e986",
            "07922e3f7faf45efaa6899a28a26cfe7",
            "24cb35f4150443c7849966c1ae25208c",
            "25d78080215b4765b38d3362f588b530",
            "8077d1def65447dcbfc9358079a874df",
            "aa57a7eeb00a4e5a950d761872aa0ff5",
            "9ce211543698483782268d7c1a2f239f",
            "8f062c21fd1f43088ad71d7382d5146a",
            "b7efa29f7e4a4f2c9d0a2cc4cdba8bb2",
            "40046cddf4ec4b8faa72e74d4f06b91c",
            "4c334530a88446668647bb777fbae042",
            "519e30221409427c91c49f7d33c5b2d0",
            "57dbe0e6068f4c86bfded4ee9fed1d60",
            "4389ee9e6f0b49519ae4c892d91cfff8",
            "d7b3f5fe81974cb6b356c457b5b3832e",
            "17bf0d82eba3412daf256e5c9d0ee48d",
            "c8f9dc14c3204b3c95558e31d8eb7a3a",
            "dfa127db6ffa4b5ba06e3e265e653dad",
            "48df61c7a94b4f0aaf17f9d5229815f3",
            "4bb86e1ea53347ecb28fee31c9c5067d",
            "fcc152e6df6446cea944ebda1fb6e862",
            "e97109b22bb04d3b8476b04ded130ef7"
          ]
        },
        "id": "n2gp9FOO1DOn",
        "outputId": "e115e4ce-6d04-4a99-a035-e6c0f638ec8f"
      },
      "source": [
        "t_len = 100\n",
        "r_len = t_len+1\n",
        "\n",
        "# years = ['2009a','2014a','2013a','2018a','2017a','2008a','2015a','2006a','2011a','2004a','2009b','2014b','2013b','2018b','2017b','2008b','2015b','2006b','2011b','2004b']\n",
        "years = ['0']\n",
        "\n",
        "for year in tqdm(years):\n",
        "\n",
        "  representations = []\n",
        "\n",
        "  for midname in tqdm(os.listdir('/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/'+year)):\n",
        "    mid = mido.MidiFile('/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/'+year+'/'+midname)\n",
        "\n",
        "    i = 0\n",
        "    total_time = 0\n",
        "    time = 0\n",
        "    representation = []\n",
        "\n",
        "    last_v = 0\n",
        "    last_event_time = 0\n",
        "\n",
        "    for msg in mid:\n",
        "\n",
        "      # 213 different events\n",
        "      # ----------------------\n",
        "      # NOTE ON starts at 0\n",
        "      # TIME-SHIFT starts at 88\n",
        "\n",
        "      #print(msg.type, msg.time,'s ',msg.time*1000,'ms')\n",
        "\n",
        "      # print(msg)\n",
        "\n",
        "\n",
        "    # get time\n",
        "      total_time+=msg.time*1000 \n",
        "      time+=msg.time*1000\n",
        "      # print(total_time, time)\n",
        "\n",
        "      # check how many seconds elapsed\n",
        "      r = time/1000\n",
        "      # if greater than 1 second \n",
        "      if r >= 1: \n",
        "        event = np.zeros(213)\n",
        "        event[212]=1\n",
        "        # then add a time_shift event for each second\n",
        "        for i in range(int(r)):\n",
        "          # print('time: ', 125, 380)\n",
        "          representation.append(event)\n",
        "          if len(representation)==r_len:   \n",
        "            representations.append(representation)\n",
        "            representation=[]\n",
        "          time-=1000\n",
        "\n",
        "      if msg.type=='note_on':\n",
        "\n",
        "        if msg.velocity != 0:\n",
        "          # then we want to save a time event\n",
        "          t = int(time/8)\n",
        "          time -= (t*8)\n",
        "          event = np.zeros(213)\n",
        "          event[88+t]=1\n",
        "          representation.append(event)\n",
        "          if len(representation)==r_len:   \n",
        "            representations.append(representation)\n",
        "            representation=[]\n",
        "\n",
        "          # then we want to save a note on event\n",
        "          event = np.zeros(213)\n",
        "          event[msg.note-21]=1\n",
        "          representation.append(event) \n",
        "          if len(representation)==r_len:   \n",
        "            representations.append(representation)\n",
        "            representation=[]\n",
        "\n",
        "  rmax = np.argmax(np.array(representations),axis=2).astype(int)\n",
        "  np.savetxt('/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/mido_100_short'+year+'.csv', rmax, fmt='%s', delimiter=',')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "446e93394a044c1dbd32f6f96931e986",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "519e30221409427c91c49f7d33c5b2d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "GVwkWOmw5ISI",
        "outputId": "f01141ea-abdc-46fe-8e65-f405829c59be"
      },
      "source": [
        "pd.read_csv('/content/drive/MyDrive/Colab Notebooks/piano_generation/maestro-v3.0.0/mido_100_short0.csv',header=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>212</td>\n",
              "      <td>92</td>\n",
              "      <td>22</td>\n",
              "      <td>89</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>23</td>\n",
              "      <td>89</td>\n",
              "      <td>11</td>\n",
              "      <td>96</td>\n",
              "      <td>25</td>\n",
              "      <td>89</td>\n",
              "      <td>13</td>\n",
              "      <td>102</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>15</td>\n",
              "      <td>212</td>\n",
              "      <td>171</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>41</td>\n",
              "      <td>90</td>\n",
              "      <td>35</td>\n",
              "      <td>90</td>\n",
              "      <td>27</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>135</td>\n",
              "      <td>33</td>\n",
              "      <td>88</td>\n",
              "      <td>42</td>\n",
              "      <td>89</td>\n",
              "      <td>38</td>\n",
              "      <td>89</td>\n",
              "      <td>23</td>\n",
              "      <td>120</td>\n",
              "      <td>39</td>\n",
              "      <td>91</td>\n",
              "      <td>18</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>8</td>\n",
              "      <td>91</td>\n",
              "      <td>20</td>\n",
              "      <td>92</td>\n",
              "      <td>10</td>\n",
              "      <td>93</td>\n",
              "      <td>22</td>\n",
              "      <td>98</td>\n",
              "      <td>11</td>\n",
              "      <td>89</td>\n",
              "      <td>23</td>\n",
              "      <td>99</td>\n",
              "      <td>13</td>\n",
              "      <td>88</td>\n",
              "      <td>25</td>\n",
              "      <td>105</td>\n",
              "      <td>15</td>\n",
              "      <td>90</td>\n",
              "      <td>27</td>\n",
              "      <td>212</td>\n",
              "      <td>154</td>\n",
              "      <td>41</td>\n",
              "      <td>90</td>\n",
              "      <td>27</td>\n",
              "      <td>89</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>35</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>156</td>\n",
              "      <td>33</td>\n",
              "      <td>89</td>\n",
              "      <td>42</td>\n",
              "      <td>90</td>\n",
              "      <td>38</td>\n",
              "      <td>88</td>\n",
              "      <td>23</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39</td>\n",
              "      <td>88</td>\n",
              "      <td>18</td>\n",
              "      <td>89</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>46</td>\n",
              "      <td>90</td>\n",
              "      <td>34</td>\n",
              "      <td>212</td>\n",
              "      <td>153</td>\n",
              "      <td>46</td>\n",
              "      <td>89</td>\n",
              "      <td>58</td>\n",
              "      <td>89</td>\n",
              "      <td>51</td>\n",
              "      <td>92</td>\n",
              "      <td>39</td>\n",
              "      <td>212</td>\n",
              "      <td>190</td>\n",
              "      <td>3</td>\n",
              "      <td>95</td>\n",
              "      <td>15</td>\n",
              "      <td>99</td>\n",
              "      <td>5</td>\n",
              "      <td>91</td>\n",
              "      <td>17</td>\n",
              "      <td>94</td>\n",
              "      <td>6</td>\n",
              "      <td>93</td>\n",
              "      <td>18</td>\n",
              "      <td>92</td>\n",
              "      <td>8</td>\n",
              "      <td>96</td>\n",
              "      <td>10</td>\n",
              "      <td>88</td>\n",
              "      <td>20</td>\n",
              "      <td>96</td>\n",
              "      <td>22</td>\n",
              "      <td>90</td>\n",
              "      <td>...</td>\n",
              "      <td>28</td>\n",
              "      <td>88</td>\n",
              "      <td>37</td>\n",
              "      <td>212</td>\n",
              "      <td>175</td>\n",
              "      <td>25</td>\n",
              "      <td>88</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>44</td>\n",
              "      <td>88</td>\n",
              "      <td>40</td>\n",
              "      <td>124</td>\n",
              "      <td>28</td>\n",
              "      <td>88</td>\n",
              "      <td>47</td>\n",
              "      <td>88</td>\n",
              "      <td>35</td>\n",
              "      <td>89</td>\n",
              "      <td>20</td>\n",
              "      <td>88</td>\n",
              "      <td>40</td>\n",
              "      <td>212</td>\n",
              "      <td>109</td>\n",
              "      <td>20</td>\n",
              "      <td>91</td>\n",
              "      <td>26</td>\n",
              "      <td>96</td>\n",
              "      <td>29</td>\n",
              "      <td>97</td>\n",
              "      <td>35</td>\n",
              "      <td>89</td>\n",
              "      <td>38</td>\n",
              "      <td>88</td>\n",
              "      <td>41</td>\n",
              "      <td>88</td>\n",
              "      <td>50</td>\n",
              "      <td>89</td>\n",
              "      <td>47</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>205</td>\n",
              "      <td>20</td>\n",
              "      <td>88</td>\n",
              "      <td>36</td>\n",
              "      <td>89</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>30</td>\n",
              "      <td>88</td>\n",
              "      <td>42</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>89</td>\n",
              "      <td>48</td>\n",
              "      <td>161</td>\n",
              "      <td>35</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>88</td>\n",
              "      <td>51</td>\n",
              "      <td>89</td>\n",
              "      <td>54</td>\n",
              "      <td>88</td>\n",
              "      <td>45</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>137</td>\n",
              "      <td>37</td>\n",
              "      <td>134</td>\n",
              "      <td>38</td>\n",
              "      <td>151</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>39</td>\n",
              "      <td>89</td>\n",
              "      <td>30</td>\n",
              "      <td>89</td>\n",
              "      <td>51</td>\n",
              "      <td>...</td>\n",
              "      <td>212</td>\n",
              "      <td>96</td>\n",
              "      <td>46</td>\n",
              "      <td>92</td>\n",
              "      <td>43</td>\n",
              "      <td>212</td>\n",
              "      <td>208</td>\n",
              "      <td>47</td>\n",
              "      <td>90</td>\n",
              "      <td>32</td>\n",
              "      <td>91</td>\n",
              "      <td>39</td>\n",
              "      <td>88</td>\n",
              "      <td>44</td>\n",
              "      <td>115</td>\n",
              "      <td>31</td>\n",
              "      <td>89</td>\n",
              "      <td>51</td>\n",
              "      <td>89</td>\n",
              "      <td>39</td>\n",
              "      <td>89</td>\n",
              "      <td>46</td>\n",
              "      <td>88</td>\n",
              "      <td>23</td>\n",
              "      <td>212</td>\n",
              "      <td>104</td>\n",
              "      <td>47</td>\n",
              "      <td>88</td>\n",
              "      <td>59</td>\n",
              "      <td>89</td>\n",
              "      <td>43</td>\n",
              "      <td>91</td>\n",
              "      <td>50</td>\n",
              "      <td>105</td>\n",
              "      <td>46</td>\n",
              "      <td>91</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>58</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>39</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>90</td>\n",
              "      <td>40</td>\n",
              "      <td>91</td>\n",
              "      <td>37</td>\n",
              "      <td>106</td>\n",
              "      <td>39</td>\n",
              "      <td>89</td>\n",
              "      <td>35</td>\n",
              "      <td>212</td>\n",
              "      <td>99</td>\n",
              "      <td>46</td>\n",
              "      <td>90</td>\n",
              "      <td>43</td>\n",
              "      <td>212</td>\n",
              "      <td>200</td>\n",
              "      <td>47</td>\n",
              "      <td>91</td>\n",
              "      <td>34</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>89</td>\n",
              "      <td>44</td>\n",
              "      <td>104</td>\n",
              "      <td>32</td>\n",
              "      <td>118</td>\n",
              "      <td>31</td>\n",
              "      <td>88</td>\n",
              "      <td>23</td>\n",
              "      <td>89</td>\n",
              "      <td>51</td>\n",
              "      <td>89</td>\n",
              "      <td>46</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>212</td>\n",
              "      <td>110</td>\n",
              "      <td>59</td>\n",
              "      <td>...</td>\n",
              "      <td>91</td>\n",
              "      <td>20</td>\n",
              "      <td>98</td>\n",
              "      <td>19</td>\n",
              "      <td>89</td>\n",
              "      <td>22</td>\n",
              "      <td>97</td>\n",
              "      <td>23</td>\n",
              "      <td>96</td>\n",
              "      <td>25</td>\n",
              "      <td>98</td>\n",
              "      <td>21</td>\n",
              "      <td>89</td>\n",
              "      <td>26</td>\n",
              "      <td>94</td>\n",
              "      <td>22</td>\n",
              "      <td>93</td>\n",
              "      <td>27</td>\n",
              "      <td>92</td>\n",
              "      <td>23</td>\n",
              "      <td>212</td>\n",
              "      <td>108</td>\n",
              "      <td>47</td>\n",
              "      <td>88</td>\n",
              "      <td>35</td>\n",
              "      <td>88</td>\n",
              "      <td>42</td>\n",
              "      <td>89</td>\n",
              "      <td>33</td>\n",
              "      <td>88</td>\n",
              "      <td>18</td>\n",
              "      <td>89</td>\n",
              "      <td>23</td>\n",
              "      <td>89</td>\n",
              "      <td>27</td>\n",
              "      <td>89</td>\n",
              "      <td>39</td>\n",
              "      <td>100</td>\n",
              "      <td>39</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>157</td>\n",
              "      <td>35</td>\n",
              "      <td>88</td>\n",
              "      <td>20</td>\n",
              "      <td>88</td>\n",
              "      <td>49</td>\n",
              "      <td>88</td>\n",
              "      <td>40</td>\n",
              "      <td>89</td>\n",
              "      <td>37</td>\n",
              "      <td>88</td>\n",
              "      <td>25</td>\n",
              "      <td>88</td>\n",
              "      <td>44</td>\n",
              "      <td>88</td>\n",
              "      <td>28</td>\n",
              "      <td>136</td>\n",
              "      <td>37</td>\n",
              "      <td>88</td>\n",
              "      <td>51</td>\n",
              "      <td>89</td>\n",
              "      <td>22</td>\n",
              "      <td>88</td>\n",
              "      <td>46</td>\n",
              "      <td>88</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>31</td>\n",
              "      <td>88</td>\n",
              "      <td>43</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>212</td>\n",
              "      <td>113</td>\n",
              "      <td>58</td>\n",
              "      <td>88</td>\n",
              "      <td>46</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>89</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>54</td>\n",
              "      <td>88</td>\n",
              "      <td>22</td>\n",
              "      <td>88</td>\n",
              "      <td>49</td>\n",
              "      <td>89</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>42</td>\n",
              "      <td>88</td>\n",
              "      <td>46</td>\n",
              "      <td>89</td>\n",
              "      <td>30</td>\n",
              "      <td>198</td>\n",
              "      <td>23</td>\n",
              "      <td>92</td>\n",
              "      <td>29</td>\n",
              "      <td>90</td>\n",
              "      <td>32</td>\n",
              "      <td>89</td>\n",
              "      <td>56</td>\n",
              "      <td>89</td>\n",
              "      <td>44</td>\n",
              "      <td>88</td>\n",
              "      <td>47</td>\n",
              "      <td>88</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>97</td>\n",
              "      <td>54</td>\n",
              "      <td>118</td>\n",
              "      <td>25</td>\n",
              "      <td>88</td>\n",
              "      <td>40</td>\n",
              "      <td>88</td>\n",
              "      <td>58</td>\n",
              "      <td>89</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3945</th>\n",
              "      <td>60</td>\n",
              "      <td>89</td>\n",
              "      <td>48</td>\n",
              "      <td>109</td>\n",
              "      <td>51</td>\n",
              "      <td>105</td>\n",
              "      <td>39</td>\n",
              "      <td>106</td>\n",
              "      <td>44</td>\n",
              "      <td>99</td>\n",
              "      <td>48</td>\n",
              "      <td>109</td>\n",
              "      <td>51</td>\n",
              "      <td>97</td>\n",
              "      <td>39</td>\n",
              "      <td>102</td>\n",
              "      <td>44</td>\n",
              "      <td>109</td>\n",
              "      <td>48</td>\n",
              "      <td>119</td>\n",
              "      <td>36</td>\n",
              "      <td>89</td>\n",
              "      <td>39</td>\n",
              "      <td>92</td>\n",
              "      <td>44</td>\n",
              "      <td>89</td>\n",
              "      <td>48</td>\n",
              "      <td>97</td>\n",
              "      <td>51</td>\n",
              "      <td>107</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>37</td>\n",
              "      <td>89</td>\n",
              "      <td>49</td>\n",
              "      <td>89</td>\n",
              "      <td>43</td>\n",
              "      <td>114</td>\n",
              "      <td>51</td>\n",
              "      <td>91</td>\n",
              "      <td>...</td>\n",
              "      <td>102</td>\n",
              "      <td>51</td>\n",
              "      <td>101</td>\n",
              "      <td>39</td>\n",
              "      <td>100</td>\n",
              "      <td>44</td>\n",
              "      <td>109</td>\n",
              "      <td>48</td>\n",
              "      <td>102</td>\n",
              "      <td>51</td>\n",
              "      <td>105</td>\n",
              "      <td>36</td>\n",
              "      <td>89</td>\n",
              "      <td>39</td>\n",
              "      <td>90</td>\n",
              "      <td>48</td>\n",
              "      <td>92</td>\n",
              "      <td>44</td>\n",
              "      <td>99</td>\n",
              "      <td>51</td>\n",
              "      <td>107</td>\n",
              "      <td>37</td>\n",
              "      <td>89</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>49</td>\n",
              "      <td>89</td>\n",
              "      <td>43</td>\n",
              "      <td>110</td>\n",
              "      <td>51</td>\n",
              "      <td>96</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>27</td>\n",
              "      <td>90</td>\n",
              "      <td>46</td>\n",
              "      <td>120</td>\n",
              "      <td>36</td>\n",
              "      <td>89</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3946</th>\n",
              "      <td>90</td>\n",
              "      <td>48</td>\n",
              "      <td>92</td>\n",
              "      <td>44</td>\n",
              "      <td>93</td>\n",
              "      <td>51</td>\n",
              "      <td>113</td>\n",
              "      <td>39</td>\n",
              "      <td>103</td>\n",
              "      <td>44</td>\n",
              "      <td>107</td>\n",
              "      <td>48</td>\n",
              "      <td>100</td>\n",
              "      <td>51</td>\n",
              "      <td>103</td>\n",
              "      <td>39</td>\n",
              "      <td>102</td>\n",
              "      <td>44</td>\n",
              "      <td>111</td>\n",
              "      <td>48</td>\n",
              "      <td>105</td>\n",
              "      <td>51</td>\n",
              "      <td>105</td>\n",
              "      <td>36</td>\n",
              "      <td>89</td>\n",
              "      <td>48</td>\n",
              "      <td>89</td>\n",
              "      <td>39</td>\n",
              "      <td>93</td>\n",
              "      <td>44</td>\n",
              "      <td>99</td>\n",
              "      <td>51</td>\n",
              "      <td>112</td>\n",
              "      <td>49</td>\n",
              "      <td>91</td>\n",
              "      <td>37</td>\n",
              "      <td>89</td>\n",
              "      <td>43</td>\n",
              "      <td>90</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>48</td>\n",
              "      <td>117</td>\n",
              "      <td>36</td>\n",
              "      <td>99</td>\n",
              "      <td>39</td>\n",
              "      <td>108</td>\n",
              "      <td>44</td>\n",
              "      <td>103</td>\n",
              "      <td>48</td>\n",
              "      <td>109</td>\n",
              "      <td>36</td>\n",
              "      <td>100</td>\n",
              "      <td>39</td>\n",
              "      <td>107</td>\n",
              "      <td>44</td>\n",
              "      <td>105</td>\n",
              "      <td>48</td>\n",
              "      <td>105</td>\n",
              "      <td>36</td>\n",
              "      <td>101</td>\n",
              "      <td>39</td>\n",
              "      <td>111</td>\n",
              "      <td>44</td>\n",
              "      <td>105</td>\n",
              "      <td>48</td>\n",
              "      <td>107</td>\n",
              "      <td>36</td>\n",
              "      <td>100</td>\n",
              "      <td>39</td>\n",
              "      <td>120</td>\n",
              "      <td>44</td>\n",
              "      <td>113</td>\n",
              "      <td>47</td>\n",
              "      <td>108</td>\n",
              "      <td>19</td>\n",
              "      <td>88</td>\n",
              "      <td>35</td>\n",
              "      <td>102</td>\n",
              "      <td>39</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3947</th>\n",
              "      <td>20</td>\n",
              "      <td>91</td>\n",
              "      <td>44</td>\n",
              "      <td>106</td>\n",
              "      <td>47</td>\n",
              "      <td>103</td>\n",
              "      <td>23</td>\n",
              "      <td>89</td>\n",
              "      <td>35</td>\n",
              "      <td>102</td>\n",
              "      <td>39</td>\n",
              "      <td>107</td>\n",
              "      <td>26</td>\n",
              "      <td>90</td>\n",
              "      <td>44</td>\n",
              "      <td>105</td>\n",
              "      <td>47</td>\n",
              "      <td>108</td>\n",
              "      <td>27</td>\n",
              "      <td>90</td>\n",
              "      <td>39</td>\n",
              "      <td>105</td>\n",
              "      <td>44</td>\n",
              "      <td>108</td>\n",
              "      <td>32</td>\n",
              "      <td>90</td>\n",
              "      <td>47</td>\n",
              "      <td>108</td>\n",
              "      <td>51</td>\n",
              "      <td>112</td>\n",
              "      <td>34</td>\n",
              "      <td>94</td>\n",
              "      <td>39</td>\n",
              "      <td>108</td>\n",
              "      <td>44</td>\n",
              "      <td>108</td>\n",
              "      <td>20</td>\n",
              "      <td>97</td>\n",
              "      <td>39</td>\n",
              "      <td>96</td>\n",
              "      <td>...</td>\n",
              "      <td>22</td>\n",
              "      <td>135</td>\n",
              "      <td>47</td>\n",
              "      <td>112</td>\n",
              "      <td>44</td>\n",
              "      <td>89</td>\n",
              "      <td>23</td>\n",
              "      <td>89</td>\n",
              "      <td>32</td>\n",
              "      <td>108</td>\n",
              "      <td>46</td>\n",
              "      <td>97</td>\n",
              "      <td>44</td>\n",
              "      <td>99</td>\n",
              "      <td>43</td>\n",
              "      <td>99</td>\n",
              "      <td>45</td>\n",
              "      <td>101</td>\n",
              "      <td>42</td>\n",
              "      <td>91</td>\n",
              "      <td>24</td>\n",
              "      <td>101</td>\n",
              "      <td>44</td>\n",
              "      <td>100</td>\n",
              "      <td>42</td>\n",
              "      <td>95</td>\n",
              "      <td>40</td>\n",
              "      <td>102</td>\n",
              "      <td>42</td>\n",
              "      <td>91</td>\n",
              "      <td>44</td>\n",
              "      <td>98</td>\n",
              "      <td>25</td>\n",
              "      <td>93</td>\n",
              "      <td>40</td>\n",
              "      <td>102</td>\n",
              "      <td>42</td>\n",
              "      <td>98</td>\n",
              "      <td>40</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3948</th>\n",
              "      <td>39</td>\n",
              "      <td>96</td>\n",
              "      <td>42</td>\n",
              "      <td>101</td>\n",
              "      <td>39</td>\n",
              "      <td>90</td>\n",
              "      <td>27</td>\n",
              "      <td>101</td>\n",
              "      <td>40</td>\n",
              "      <td>98</td>\n",
              "      <td>39</td>\n",
              "      <td>98</td>\n",
              "      <td>37</td>\n",
              "      <td>102</td>\n",
              "      <td>40</td>\n",
              "      <td>100</td>\n",
              "      <td>28</td>\n",
              "      <td>89</td>\n",
              "      <td>37</td>\n",
              "      <td>101</td>\n",
              "      <td>40</td>\n",
              "      <td>104</td>\n",
              "      <td>37</td>\n",
              "      <td>89</td>\n",
              "      <td>28</td>\n",
              "      <td>89</td>\n",
              "      <td>32</td>\n",
              "      <td>99</td>\n",
              "      <td>40</td>\n",
              "      <td>104</td>\n",
              "      <td>35</td>\n",
              "      <td>89</td>\n",
              "      <td>30</td>\n",
              "      <td>88</td>\n",
              "      <td>27</td>\n",
              "      <td>101</td>\n",
              "      <td>40</td>\n",
              "      <td>102</td>\n",
              "      <td>30</td>\n",
              "      <td>89</td>\n",
              "      <td>...</td>\n",
              "      <td>95</td>\n",
              "      <td>27</td>\n",
              "      <td>89</td>\n",
              "      <td>23</td>\n",
              "      <td>90</td>\n",
              "      <td>32</td>\n",
              "      <td>101</td>\n",
              "      <td>40</td>\n",
              "      <td>101</td>\n",
              "      <td>32</td>\n",
              "      <td>89</td>\n",
              "      <td>27</td>\n",
              "      <td>89</td>\n",
              "      <td>23</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>108</td>\n",
              "      <td>25</td>\n",
              "      <td>88</td>\n",
              "      <td>22</td>\n",
              "      <td>88</td>\n",
              "      <td>31</td>\n",
              "      <td>173</td>\n",
              "      <td>52</td>\n",
              "      <td>89</td>\n",
              "      <td>34</td>\n",
              "      <td>88</td>\n",
              "      <td>37</td>\n",
              "      <td>88</td>\n",
              "      <td>49</td>\n",
              "      <td>88</td>\n",
              "      <td>31</td>\n",
              "      <td>88</td>\n",
              "      <td>40</td>\n",
              "      <td>88</td>\n",
              "      <td>46</td>\n",
              "      <td>212</td>\n",
              "      <td>165</td>\n",
              "      <td>51</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3949</th>\n",
              "      <td>52</td>\n",
              "      <td>98</td>\n",
              "      <td>54</td>\n",
              "      <td>103</td>\n",
              "      <td>52</td>\n",
              "      <td>150</td>\n",
              "      <td>51</td>\n",
              "      <td>116</td>\n",
              "      <td>51</td>\n",
              "      <td>89</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>35</td>\n",
              "      <td>126</td>\n",
              "      <td>59</td>\n",
              "      <td>114</td>\n",
              "      <td>58</td>\n",
              "      <td>114</td>\n",
              "      <td>56</td>\n",
              "      <td>109</td>\n",
              "      <td>51</td>\n",
              "      <td>110</td>\n",
              "      <td>47</td>\n",
              "      <td>114</td>\n",
              "      <td>46</td>\n",
              "      <td>88</td>\n",
              "      <td>25</td>\n",
              "      <td>89</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>28</td>\n",
              "      <td>115</td>\n",
              "      <td>54</td>\n",
              "      <td>111</td>\n",
              "      <td>51</td>\n",
              "      <td>109</td>\n",
              "      <td>52</td>\n",
              "      <td>112</td>\n",
              "      <td>49</td>\n",
              "      <td>106</td>\n",
              "      <td>...</td>\n",
              "      <td>111</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>35</td>\n",
              "      <td>127</td>\n",
              "      <td>37</td>\n",
              "      <td>89</td>\n",
              "      <td>43</td>\n",
              "      <td>88</td>\n",
              "      <td>27</td>\n",
              "      <td>90</td>\n",
              "      <td>40</td>\n",
              "      <td>185</td>\n",
              "      <td>39</td>\n",
              "      <td>89</td>\n",
              "      <td>35</td>\n",
              "      <td>136</td>\n",
              "      <td>37</td>\n",
              "      <td>91</td>\n",
              "      <td>34</td>\n",
              "      <td>143</td>\n",
              "      <td>27</td>\n",
              "      <td>90</td>\n",
              "      <td>44</td>\n",
              "      <td>130</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>35</td>\n",
              "      <td>111</td>\n",
              "      <td>37</td>\n",
              "      <td>93</td>\n",
              "      <td>34</td>\n",
              "      <td>108</td>\n",
              "      <td>35</td>\n",
              "      <td>91</td>\n",
              "      <td>39</td>\n",
              "      <td>111</td>\n",
              "      <td>34</td>\n",
              "      <td>90</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3950 rows × 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3    4    5    6    ...  94   95   96   97   98   99   100\n",
              "0     212   92   22   89   10  100   23  ...   89   42   90   38   88   23  126\n",
              "1      39   88   18   89   27   88   46  ...   88   41   88   50   89   47  212\n",
              "2     205   20   88   36   89   27   88  ...  105   46   91   51   88   58   91\n",
              "3      39  212  212   90   40   91   37  ...   89   27   89   39  100   39  212\n",
              "4     157   35   88   20   88   49   88  ...   25   88   40   88   58   89   34\n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "3945   60   89   48  109   51  105   39  ...   27   90   46  120   36   89   32\n",
              "3946   90   48   92   44   93   51  113  ...  108   19   88   35  102   39  108\n",
              "3947   20   91   44  106   47  103   23  ...   93   40  102   42   98   40  100\n",
              "3948   39   96   42  101   39   90   27  ...   40   88   46  212  165   51  101\n",
              "3949   52   98   54  103   52  150   51  ...   35   91   39  111   34   90   37\n",
              "\n",
              "[3950 rows x 101 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13JljFPu8-R_"
      },
      "source": [
        "## Convert to MIDI 213"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQpDCqggvhYe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "9f2fa04c-5488-435f-baa9-993b6f43371d"
      },
      "source": [
        "new_pred = np.expand_dims(new_pred[2],0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-337b3540bf52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFjjKGpOfSeT",
        "outputId": "ab9b4200-59fa-4ed0-ab05-db2c1bd34c31"
      },
      "source": [
        "new_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 101, 413)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RB3AobyuN4X",
        "outputId": "7ae26e28-7d36-47c5-9335-9165cb65549f"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[9.5289e-03, 8.9877e-03, 8.4953e-03,  ..., 9.9051e-03, 9.1890e-03, 5.8481e-03],\n",
              "         [9.9495e-03, 1.0150e-02, 9.8334e-03,  ..., 9.0563e-03, 8.5269e-03, 1.1825e-02],\n",
              "         [9.4802e-03, 7.4423e-03, 8.3112e-03,  ..., 1.0373e-02, 1.0604e-02, 1.2105e-02],\n",
              "         ...,\n",
              "         [9.9625e-03, 9.3065e-03, 9.5493e-03,  ..., 9.3143e-03, 1.0053e-02, 5.4974e-03],\n",
              "         [9.6761e-03, 9.5058e-03, 9.6339e-03,  ..., 8.9657e-03, 8.9058e-03, 7.0971e-03],\n",
              "         [9.5549e-03, 9.0121e-03, 8.7494e-03,  ..., 9.7650e-03, 1.0358e-02, 8.3889e-03]],\n",
              "\n",
              "        [[9.5609e-03, 8.6016e-03, 9.6783e-03,  ..., 1.3353e-02, 1.1113e-02, 9.2699e-03],\n",
              "         [9.8197e-03, 9.7993e-03, 9.0923e-03,  ..., 1.0240e-02, 1.1128e-02, 9.5561e-03],\n",
              "         [9.6442e-03, 9.1745e-03, 9.3835e-03,  ..., 9.8386e-03, 9.3619e-03, 9.2946e-03],\n",
              "         ...,\n",
              "         [9.8440e-03, 1.0025e-02, 1.0209e-02,  ..., 9.6969e-03, 9.6437e-03, 9.3651e-03],\n",
              "         [9.9268e-03, 9.8254e-03, 9.6369e-03,  ..., 9.7689e-03, 9.7611e-03, 1.4770e-02],\n",
              "         [9.7714e-03, 8.8416e-03, 9.1821e-03,  ..., 8.1005e-03, 8.2103e-03, 1.6670e-02]],\n",
              "\n",
              "        [[9.5377e-03, 7.2743e-03, 9.9025e-03,  ..., 1.4780e-02, 1.2215e-02, 4.5479e-03],\n",
              "         [9.6953e-03, 8.7540e-03, 9.8875e-03,  ..., 1.2479e-02, 1.1146e-02, 1.4000e-02],\n",
              "         [9.8544e-03, 9.2429e-03, 9.4926e-03,  ..., 1.0014e-02, 1.0499e-02, 1.0562e-02],\n",
              "         ...,\n",
              "         [9.9978e-03, 1.0513e-02, 9.5823e-03,  ..., 1.0116e-02, 1.0532e-02, 7.5238e-03],\n",
              "         [9.9530e-03, 1.0713e-02, 9.8698e-03,  ..., 1.0434e-02, 1.0128e-02, 6.7223e-03],\n",
              "         [1.2167e-02, 1.5698e-02, 1.3917e-02,  ..., 9.2214e-03, 9.7924e-03, 7.7037e-03]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[9.4792e-03, 9.5840e-03, 9.0293e-03,  ..., 1.3845e-02, 1.0835e-02, 1.7539e-05],\n",
              "         [1.0543e-02, 1.1701e-02, 1.0635e-02,  ..., 9.5146e-03, 9.5425e-03, 5.1745e-05],\n",
              "         [9.6996e-03, 9.5781e-03, 9.3509e-03,  ..., 9.6414e-03, 1.0374e-02, 3.0864e-05],\n",
              "         ...,\n",
              "         [9.8468e-03, 1.0060e-02, 1.0184e-02,  ..., 1.0194e-02, 9.6221e-03, 3.5196e-05],\n",
              "         [9.9292e-03, 1.2176e-02, 1.0631e-02,  ..., 9.6196e-03, 9.9257e-03, 2.9133e-05],\n",
              "         [9.7583e-03, 9.4865e-03, 9.5414e-03,  ..., 1.0537e-02, 1.0527e-02, 1.3948e-05]],\n",
              "\n",
              "        [[9.5162e-03, 9.2573e-03, 8.7890e-03,  ..., 1.0982e-02, 1.0068e-02, 1.3910e-02],\n",
              "         [9.4953e-03, 9.9936e-03, 9.4655e-03,  ..., 1.0401e-02, 9.7872e-03, 1.0331e-02],\n",
              "         [1.0329e-02, 1.0575e-02, 1.0515e-02,  ..., 1.0238e-02, 1.0375e-02, 6.1856e-03],\n",
              "         ...,\n",
              "         [9.9064e-03, 9.4603e-03, 1.0066e-02,  ..., 9.9931e-03, 1.0031e-02, 1.3330e-02],\n",
              "         [9.8229e-03, 1.0017e-02, 1.0354e-02,  ..., 1.0365e-02, 1.0115e-02, 1.1833e-02],\n",
              "         [1.0097e-02, 1.0138e-02, 9.7572e-03,  ..., 9.3192e-03, 1.0064e-02, 5.4061e-03]],\n",
              "\n",
              "        [[1.0211e-02, 1.0672e-02, 1.0366e-02,  ..., 1.1031e-02, 1.0175e-02, 4.7414e-03],\n",
              "         [9.6079e-03, 8.7657e-03, 9.3142e-03,  ..., 9.7775e-03, 8.9410e-03, 9.5250e-03],\n",
              "         [9.9073e-03, 9.5393e-03, 1.0390e-02,  ..., 1.0523e-02, 1.0377e-02, 1.0290e-02],\n",
              "         ...,\n",
              "         [9.8792e-03, 1.0147e-02, 1.0156e-02,  ..., 1.0535e-02, 9.8136e-03, 1.2535e-02],\n",
              "         [9.7292e-03, 1.0217e-02, 9.3801e-03,  ..., 9.5490e-03, 9.9126e-03, 1.0375e-02],\n",
              "         [9.7689e-03, 1.0129e-02, 9.5708e-03,  ..., 9.8772e-03, 9.2308e-03, 1.0975e-02]]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0n4sZya-K5v"
      },
      "source": [
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxdlIIhDzIzc"
      },
      "source": [
        "ones = np.random.randint(0,213,(1,101))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa6x3fSNuNWj"
      },
      "source": [
        "new_pred = ones[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_5q9ASerXtT",
        "outputId": "e47610aa-f699-4299-da2c-aeceea5745ac"
      },
      "source": [
        "new_pred = new_pred.unsqueeze(0)\n",
        "new_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 16, 138,  23,  90,  38,  90,  49,  95,  31, 116,  31, 114,  65, 117,  38,  88,  28,  89,  35, 114,  31, 118,  31, 101,  31, 119,  40,  89,  67,  88,  37,  92,  30, 111,  27, 116,  64, 119,  58, 113,  41,  92,  28,  89,  38,  92,  33, 110,  26, 116,  26, 115,  19,  88,  57,  90,  40, 116,  45,  89,  41,  88,  64, 116,  15,  93,  31, 123,  14, 104,  18,  88,  45,  91,  61, 120,  26, 118,  45,  89,  27,  88,  41,  90,  35, 111,  47, 109,  63,  90,  45,  89,  41,  91,  36, 108,  24, 117,  24, 116,  22]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK6N2MzZriVF",
        "outputId": "0fbf6fd1-5628-4380-c89e-f5bbad37dcb2"
      },
      "source": [
        "new_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27, 137,  49, 114,  29,  16,  35, 116, 141, 149, 141, 198,  28, 116,  29, 121,  49,  89,  35, 198,  14, 132,  54, 126,  54, 123,  31,  89,  27, 120,  49, 112,  54, 126,  58, 177,  58, 139, 184,  98,  41, 133,  43,  89,  37, 112,  60, 138,  64, 177,  64, 155,  49, 121,   8, 103,  65, 177,  34,  89,  41, 121,  58, 149,  64, 160,  64, 158,  43, 117,  43, 134,  34,  91,  60, 124,  64, 132,  34,  89,  43, 121,  41, 119,  35, 124,  64, 160, 123, 103,  34,  89,  41,  48,  39, 131,  37, 116,  37, 149,  18]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoPlFDDDMIjo"
      },
      "source": [
        "# new_pred=new_pred.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X22iL4QXMS7X"
      },
      "source": [
        "# new_pred = new_pred.unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAwoZcpV9BT9"
      },
      "source": [
        "for repr in new_pred:\n",
        "  print(repr.shape)\n",
        "  velocity = 0\n",
        "  time = 0\n",
        "  t = 0\n",
        "  track = mido.MidiTrack()\n",
        "  for r in repr:\n",
        "    # rr = int(np.argmax(r))\n",
        "\n",
        "    rr = int(r)\n",
        "    if rr >=88:\n",
        "      time += (rr-88)*8/1000\n",
        "      t = int(mido.second2tick(time, 384, 500000))\n",
        "    elif rr < 88:\n",
        "      note = rr+21\n",
        "      print(t)\n",
        "      print(note)\n",
        "      # print(velocity)\n",
        "      track.append(mido.Message('note_on', note=note, time=t, velocity=80))\n",
        "      t = 0\n",
        "      time = 0\n",
        "    else: print('wtf!')\n",
        "\n",
        "  mid_f = mido.MidiFile(type=1, ticks_per_beat=384)\n",
        "\n",
        "  meta_track = mido.MidiTrack()\n",
        "  meta_track.append(mido.MetaMessage('set_tempo', tempo=500000, time=0))\n",
        "  meta_track.append(mido.MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0))\n",
        "  meta_track.append(mido.MetaMessage('end_of_track', time=1))\n",
        "\n",
        "  mid_f.tracks.append(meta_track)\n",
        "  mid_f.tracks.append(track)\n",
        "\n",
        "  mid_f.save('/content/drive/MyDrive/Colab Notebooks/piano_generation/gen/'+composer+ str(count) +'.midi')\n",
        "  count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZum5qoDtakC"
      },
      "source": [
        "## 88 to MIDI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHDF5zPZt9un"
      },
      "source": [
        "count = 1\n",
        "composer='88test_'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTGE23l7uA2Y"
      },
      "source": [
        "new_pred = torch.argmax(test_tensor,axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sirxqvRYxwW0"
      },
      "source": [
        "new_pred = ones[-1].unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqWR0NivuFBy"
      },
      "source": [
        "new_pred = new_pred[-1].unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTkwxW-nuk9j",
        "outputId": "0b96ee47-4b1f-429d-bb72-bcc5bb1d81c8"
      },
      "source": [
        "new_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OafD1oqdtaVe",
        "outputId": "2153e279-a0e7-4aa2-a631-669007ab99d8"
      },
      "source": [
        "count = 1\n",
        "composer='88test_'\n",
        "\n",
        "for repr in new_pred:\n",
        "  print(repr.shape)\n",
        "  velocity = 0\n",
        "  t = 0\n",
        "  track = mido.MidiTrack()\n",
        "  for r in repr:\n",
        "    # rr = int(np.argmax(r))\n",
        "\n",
        "    rr = int(r)\n",
        "      \n",
        "    if rr < 88:\n",
        "      note = rr+21\n",
        "      print(note)\n",
        "      t = int(mido.second2tick(0.25, 384, 500000))\n",
        "      track.append(mido.Message('note_on', note=note, time=0, velocity=80))\n",
        "      track.append(mido.Message('note_off', note=note, time=t, velocity=80))\n",
        "      t = 0\n",
        "    else: print('wtf!')\n",
        "\n",
        "  mid_f = mido.MidiFile(type=1, ticks_per_beat=384)\n",
        "\n",
        "  meta_track = mido.MidiTrack()\n",
        "  meta_track.append(mido.MetaMessage('set_tempo', tempo=500000, time=0))\n",
        "  meta_track.append(mido.MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0))\n",
        "  meta_track.append(mido.MetaMessage('end_of_track', time=1))\n",
        "\n",
        "  mid_f.tracks.append(meta_track)\n",
        "  mid_f.tracks.append(track)\n",
        "\n",
        "  mid_f.save('/content/drive/MyDrive/Colab Notebooks/piano_generation/gen/'+composer+ str(count) +'.midi')\n",
        "  count+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10])\n",
            "86\n",
            "86\n",
            "88\n",
            "90\n",
            "90\n",
            "93\n",
            "85\n",
            "83\n",
            "88\n",
            "88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mmm13gGg6LQ"
      },
      "source": [
        "# rep = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/piano_generation/training_data copy/combined.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6pHmvtPlgVE"
      },
      "source": [
        "# t_len = 100\n",
        "# r_len = t_len+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akWNeAqrTsNb"
      },
      "source": [
        "# # mid = mido.MidiFile('/content/drive/MyDrive/Colab Notebooks/piano_generation/midi/MIDI-Unprocessed_09_R2_2009_01_ORIG_MID--AUDIO_09_R2_2009_09_R2_2009_03_WAV.midi')    \n",
        "\n",
        "\n",
        "# composer = 'debussy'\n",
        "# t_len = 100\n",
        "# r_len = t_len+1\n",
        "\n",
        "# representations = []\n",
        "\n",
        "# for midname in os.listdir('/content/drive/MyDrive/Colab Notebooks/piano_generation/'+composer):\n",
        "#   mid = mido.MidiFile('/content/drive/MyDrive/Colab Notebooks/piano_generation/'+composer+'/'+midname)\n",
        "\n",
        "#   i = 0\n",
        "#   total_time = 0\n",
        "#   time = 0\n",
        "#   representation = []\n",
        "\n",
        "#   last_v = 0\n",
        "#   last_event_time = 0\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "#   for msg in mid:\n",
        "\n",
        "#     # 413 different events\n",
        "#     # ----------------------\n",
        "#     # NOTE ON starts at 0\n",
        "#     # NOTE OFF starts at 128\n",
        "#     # TIME-SHIFT starts at 256\n",
        "#     # VELOCITY STARTS AT 381 \n",
        "\n",
        "#     #print(msg.type, msg.time,'s ',msg.time*1000,'ms')\n",
        "\n",
        "#     # print(msg)\n",
        "\n",
        "\n",
        "#   # get time\n",
        "#     total_time+=msg.time*1000 \n",
        "#     time+=msg.time*1000\n",
        "#     # print(total_time, time)\n",
        "\n",
        "#     # check how many seconds elapsed\n",
        "#     r = time/1000\n",
        "#     # if greater than 1 second \n",
        "#     if r > 1: \n",
        "#       event = np.zeros(413)\n",
        "#       event[380]=1\n",
        "#       # then add a time_shift event for each second\n",
        "#       for i in range(int(r)):\n",
        "#         # print('time: ', 125, 380)\n",
        "#         representation.append(event)\n",
        "#         if len(representation)==r_len:   \n",
        "#           representations.append(representation)\n",
        "#           representation=[]\n",
        "#         time-=1000\n",
        "\n",
        "#     if msg.type=='note_on':\n",
        "#       # then we want to save a time event\n",
        "#       t = int(time/8)\n",
        "#       time -= (t*8)\n",
        "#       event = np.zeros(413)\n",
        "#       event[256+t]=1\n",
        "#       # print('time: ', t, 256+t)\n",
        "#       representation.append(event)\n",
        "#       if len(representation)==r_len:   \n",
        "#         representations.append(representation)\n",
        "#         representation=[]\n",
        "\n",
        "#       if msg.velocity == 0:\n",
        "#   # get note off\n",
        "#         # print('off: ', msg.note, 128+msg.note)\n",
        "#         event = np.zeros(413)\n",
        "#         event[128+msg.note]=1\n",
        "#         representation.append(event)\n",
        "#         if len(representation)==r_len:   \n",
        "#           representations.append(representation)\n",
        "#           representation=[]    \n",
        "#       else:\n",
        "#   # get velocity   \n",
        "#         # print('velocity: ', msg.velocity)\n",
        "#         v = msg.velocity//4\n",
        "#         if v != last_v:\n",
        "#           event = np.zeros(413)\n",
        "#           event[381+v]=1\n",
        "#         # print('velocity: ', v, 381+v)\n",
        "#         representation.append(event)\n",
        "#         if len(representation)==r_len:   \n",
        "#           representations.append(representation)\n",
        "#           representation=[]\n",
        "#         # print('velocity_bin: ', v)\n",
        "#   # get note on\n",
        "#         # print('on: ', msg.note, msg.note)\n",
        "#         event = np.zeros(413)\n",
        "#         event[msg.note]=1\n",
        "#         representation.append(event) \n",
        "#         if len(representation)==r_len:   \n",
        "#           representations.append(representation)\n",
        "#           representation=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcOl42kH0q9A"
      },
      "source": [
        "# rmax = [2,3,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "gK6VIcsOUckA",
        "outputId": "772eacf9-cf5f-401e-d850-05903ba8fe8d"
      },
      "source": [
        "# print(len(representations))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-59055c32c440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepresentations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'representations' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAoH9wArxHfl"
      },
      "source": [
        "rep = np.array(representations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWMjJ6E9s_lL"
      },
      "source": [
        "r2 = rep.reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa5hWbL7uiLW",
        "outputId": "4fa9d3f4-d331-4bfd-9f66-bf3860ab7fca"
      },
      "source": [
        "r2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(394104424,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvFtJR7nMUBq"
      },
      "source": [
        "# np.save('/content/drive/MyDrive/Colab Notebooks/piano_generation/debussy_100',rep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uslBdWdqMi_J"
      },
      "source": [
        "rep = np.load('/content/drive/MyDrive/Colab Notebooks/piano_generation/debussy_100.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k_PF8ZENCTM"
      },
      "source": [
        "rmax = np.argmax(rep,axis=2).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEuU5tEzw3bf",
        "outputId": "3a2f098a-7340-4d56-a911-0716dfce7201"
      },
      "source": [
        "rmax[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([378, 389,  65, 265, 193, 257, 389,  67, 263, 195, 260, 386,  69,\n",
              "       260, 390,  70, 259, 197, 260, 198, 258, 392,  68, 264, 196, 259,\n",
              "       390,  66, 261, 194, 259, 391,  65, 264, 193, 259, 389,  67, 262,\n",
              "       195, 257, 390,  69, 261, 197, 261, 390,  70, 261, 198, 259, 391,\n",
              "        68, 263, 391,  66, 257, 196, 261, 194, 258, 390,  65, 263, 193,\n",
              "       258, 391,  67, 262, 195, 258, 391,  69, 262, 197, 261, 391,  70,\n",
              "       261, 198, 260, 389,  68, 263, 390,  66, 256, 196, 261, 194, 258,\n",
              "       392,  65, 264, 193, 256, 391,  67, 264, 195, 259])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMwmySUmqRuT"
      },
      "source": [
        "np.savetxt('/content/drive/MyDrive/Colab Notebooks/piano_generation/debussy_100.csv', rmax, fmt='%s', delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEIDR_mxQJHe"
      },
      "source": [
        "x_sequences = []\n",
        "y_sequences = []\n",
        "for i in range(10):\n",
        "  x = torch.tensor(rep[i][:t_len], dtype=torch.float)\n",
        "  y = torch.tensor(rep[i][1:r_len], dtype=torch.float)\n",
        "  x_sequences.append(x)\n",
        "  y_sequences.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnia5jxwQztR",
        "outputId": "693ddd69-2f6e-494c-bc91-a2d7db88b88b"
      },
      "source": [
        "y_sequences[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 413])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dKm2Z0mRMAl"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMfZmKwYRNtO"
      },
      "source": [
        "x_seq = pack_sequence(x_sequences, enforce_sorted = False)\n",
        "y_seq = pack_sequence(y_sequences, enforce_sorted = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnYDQ56ARUGm",
        "outputId": "f56a0224-31cf-4548-8fc9-dde682d93c4f"
      },
      "source": [
        "x_seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]]), batch_sizes=tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10]), sorted_indices=tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), unsorted_indices=tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCDV1-TEyHk0"
      },
      "source": [
        "# rep = rep.argmax(axis=2)\n",
        "# rep = np.expand_dims(rep, axis=2)\n",
        "# rep.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyuU6RcUY0Xc"
      },
      "source": [
        "# batch_size = len(representations)\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKBcNxZIyQ5h",
        "outputId": "b2afadd4-a6e4-4791-d6cf-69c9b82a43f8"
      },
      "source": [
        "input_seq = rep[:batch_size,:t_len,:]\n",
        "input_seq = torch.from_numpy(input_seq).float()\n",
        "input_seq.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 100, 413])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc9jqXhiydxf",
        "outputId": "b1c02271-a1c0-4b70-9dad-30f882e671d5"
      },
      "source": [
        "target_seq = rep[:batch_size,1:r_len,:]\n",
        "target_seq = torch.from_numpy(target_seq).float()\n",
        "target_seq.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 100, 413])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2Lu9-mcjbuv"
      },
      "source": [
        "# target_seq = input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QZZfuzXGymDC",
        "outputId": "d96e78fa-6d55-4920-d336-eca27f07d9d2"
      },
      "source": [
        "input_seq.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbm70CFy0YVc",
        "outputId": "3f003107-c9e5-4cc1-e5ca-a33a66b8ed8a"
      },
      "source": [
        "input_seq[:,1,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nvwvqpQv7SR"
      },
      "source": [
        "device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZH8GDwU7ZeO"
      },
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(input_seq, target_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROu1IMWFiuCQ",
        "outputId": "84cae481-e300-452a-f804-1d5dae847e8d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([100, 413])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrD0pP00oBrX"
      },
      "source": [
        "\n",
        "\n",
        "# def collate_fn(batch):\n",
        "#     x = [item[0] for item in batch]\n",
        "#     y = [item[1] for item in batch]\n",
        "#     print('p')\n",
        "#     return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXhAKiYjkJwQ"
      },
      "source": [
        "## Other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL1xX6MeqCmC"
      },
      "source": [
        "count = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy8oLHr4aDS5"
      },
      "source": [
        "for repr in representations:\n",
        "  velocity = 0\n",
        "  time = 0\n",
        "  t = 0\n",
        "  track = mido.MidiTrack()\n",
        "  for r in repr:\n",
        "    rr = np.argmax(r)\n",
        "\n",
        "    # 413 different events\n",
        "    # ----------------------\n",
        "    # NOTE ON starts at 0\n",
        "    # NOTE OFF starts at 128\n",
        "    # TIME-SHIFT starts at 256\n",
        "    # VELOCITY STARTS AT 381 \n",
        "\n",
        "    if rr >=381:\n",
        "      velocity = (rr-381)*4\n",
        "      \n",
        "    elif rr >=256:\n",
        "      time += (rr-256)*8/1000\n",
        "      t = int(mido.second2tick(time, 384, 500000))\n",
        "    elif rr >=128:\n",
        "      note = rr-128\n",
        "      track.append(mido.Message('note_on', note=note, time=t, velocity=0))\n",
        "      time = 0\n",
        "    elif rr < 128:\n",
        "      note = rr\n",
        "      # print(t)\n",
        "      # print(velocity)\n",
        "      track.append(mido.Message('note_on', note=note, time=t, velocity=velocity))\n",
        "      time = 0\n",
        "    else: print('wtf!')\n",
        "\n",
        "  mid_f = mido.MidiFile(type=1, ticks_per_beat=384)\n",
        "\n",
        "  meta_track = mido.MidiTrack()\n",
        "  meta_track.append(mido.MetaMessage('set_tempo', tempo=500000, time=0))\n",
        "  meta_track.append(mido.MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0))\n",
        "  meta_track.append(mido.MetaMessage('end_of_track', time=1))\n",
        "\n",
        "  mid_f.tracks.append(meta_track)\n",
        "  mid_f.tracks.append(track)\n",
        "\n",
        "  mid_f.save('/content/drive/MyDrive/Colab Notebooks/piano_generation/gen/'+composer+'xx'+str(count) +'.midi')\n",
        "  count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4WdK4WKqJ7q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}